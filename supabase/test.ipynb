{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac305a3e",
   "metadata": {},
   "source": [
    "## Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cf21757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from supabase import create_client\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "SUPABASE_URL = os.getenv(\"SUPABASE_URL\")\n",
    "SUPABASE_KEY = os.getenv(\"SUPABASE_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b9e08c",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7e068a",
   "metadata": {},
   "source": [
    "### Embed First 3 Benefits Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25e6542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_benefits_chunks():\n",
    "    \"\"\"\n",
    "    Embed the first 3 chunks from benefits_wellbeing_with_context.json \n",
    "    into Supabase test_chunks table (only if they don't already exist)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize clients\n",
    "    print(\"Initializing clients...\")\n",
    "    openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
    "    \n",
    "    # Check what chunks already exist\n",
    "    print(\"Checking for existing chunks...\")\n",
    "    try:\n",
    "        existing_chunks = supabase.table(\"test_chunks\").select(\"source_file, chunk_index, chunk_heading\").execute()\n",
    "        existing_set = set()\n",
    "        for chunk in existing_chunks.data:\n",
    "            key = (chunk['source_file'], chunk['chunk_index'])\n",
    "            existing_set.add(key)\n",
    "            print(f\"  ğŸ“‹ Found existing: {chunk['chunk_heading']} (index {chunk['chunk_index']})\")\n",
    "        \n",
    "        print(f\"ğŸ“Š Found {len(existing_chunks.data)} existing chunks in database\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error checking existing chunks: {e}\")\n",
    "        existing_set = set()\n",
    "    \n",
    "    # Load the benefits data\n",
    "    print(\"\\nLoading benefits data...\")\n",
    "    with open(\"data/benefits_wellbeing_with_context.json\", \"r\") as f:\n",
    "        benefits_data = json.load(f)\n",
    "    \n",
    "    # Take first 3 chunks for testing\n",
    "    test_chunks = benefits_data[:3]\n",
    "    print(f\"ğŸ“Š Processing {len(test_chunks)} chunks...\")\n",
    "    \n",
    "    # Track what we actually process\n",
    "    processed_count = 0\n",
    "    skipped_count = 0\n",
    "    \n",
    "    # Process each chunk\n",
    "    for i, chunk in enumerate(test_chunks):\n",
    "        source_file = \"benefits_wellbeing_with_context.json\"\n",
    "        chunk_key = (source_file, i)\n",
    "        \n",
    "        print(f\"\\nProcessing chunk {i+1}: {chunk['chunk_heading']}\")\n",
    "        \n",
    "        # Check if this chunk already exists\n",
    "        if chunk_key in existing_set:\n",
    "            print(f\"Skipping - chunk already exists in database\")\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "        \n",
    "        # Prepare content for embedding (combine heading + text for better context)\n",
    "        embedding_content = f\"{chunk['chunk_heading']}\\n\\n{chunk['text']}\"\n",
    "        \n",
    "        # Generate embedding\n",
    "        print(f\"ğŸ§  Generating embedding for '{chunk['chunk_heading']}'...\")\n",
    "        try:\n",
    "            response = openai_client.embeddings.create(\n",
    "                model=\"text-embedding-3-small\",\n",
    "                input=embedding_content\n",
    "            )\n",
    "            embedding = response.data[0].embedding\n",
    "            print(f\"âœ… Generated embedding with {len(embedding)} dimensions\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error generating embedding: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Prepare data for insertion\n",
    "        chunk_data = {\n",
    "            \"source_file\": source_file,\n",
    "            \"chunk_index\": i,\n",
    "            \"chunk_heading\": chunk[\"chunk_heading\"],\n",
    "            \"content\": chunk[\"text\"],\n",
    "            \"situational_context\": chunk[\"situational_context\"],\n",
    "            \"embedding\": embedding\n",
    "        }\n",
    "        \n",
    "        # Insert into Supabase\n",
    "        print(f\"ğŸ’¾ Inserting chunk into Supabase...\")\n",
    "        try:\n",
    "            result = supabase.table(\"test_chunks\").insert(chunk_data).execute()\n",
    "            print(f\"âœ… Successfully inserted chunk: {chunk['chunk_heading']}\")\n",
    "            processed_count += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error inserting into Supabase: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\nğŸ‰ Processing complete!\")\n",
    "    print(f\"   âœ… Newly embedded: {processed_count} chunks\")\n",
    "    print(f\"   â­ï¸  Skipped existing: {skipped_count} chunks\")\n",
    "    print(f\"   ğŸ“Š Total chunks: {processed_count + skipped_count}\")\n",
    "    \n",
    "    # Test a simple query\n",
    "    print(\"\\nğŸ” Final database state...\")\n",
    "    try:\n",
    "        test_query = supabase.table(\"test_chunks\").select(\"*\").execute()\n",
    "        print(f\"ğŸ“Š Total chunks in database: {len(test_query.data)}\")\n",
    "        for chunk in test_query.data:\n",
    "            print(f\"  - {chunk['chunk_heading']} (ID: {chunk['id'][:8]}...)\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error testing retrieval: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9223def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_similarity_search(query_text=\"health insurance plans\"):\n",
    "    \"\"\"\n",
    "    Similarity search that handles embedding data types correctly\n",
    "    \"\"\"\n",
    "    print(f\"\\nğŸ” Testing similarity search for: '{query_text}'\")\n",
    "    \n",
    "    # Initialize clients\n",
    "    openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
    "    \n",
    "    try:\n",
    "        # Generate embedding for query\n",
    "        print(\"ğŸ§  Generating query embedding...\")\n",
    "        response = openai_client.embeddings.create(\n",
    "            model=\"text-embedding-3-small\",\n",
    "            input=query_text\n",
    "        )\n",
    "        query_embedding = response.data[0].embedding\n",
    "        \n",
    "        # Get all chunks\n",
    "        print(\"ğŸ” Retrieving chunks from database...\")\n",
    "        all_chunks = supabase.table(\"test_chunks\").select(\"*\").execute()\n",
    "        print(f\"ğŸ“Š Retrieved {len(all_chunks.data)} chunks for similarity comparison\")\n",
    "        \n",
    "        # Debug: Check what type the embedding is\n",
    "        if all_chunks.data:\n",
    "            sample_embedding = all_chunks.data[0]['embedding']\n",
    "            print(f\"ğŸ” Debug - Embedding type: {type(sample_embedding)}\")\n",
    "            print(f\"ğŸ” Debug - Embedding preview: {str(sample_embedding)[:100]}...\")\n",
    "        \n",
    "        # Calculate similarities with proper type handling\n",
    "        import numpy as np\n",
    "        similarities = []\n",
    "        \n",
    "        for chunk in all_chunks.data:\n",
    "            if chunk['embedding']:\n",
    "                # Handle different embedding formats from Supabase\n",
    "                chunk_embedding = chunk['embedding']\n",
    "                \n",
    "                # Convert to numpy array if it's a list or string\n",
    "                if isinstance(chunk_embedding, list):\n",
    "                    chunk_embedding = np.array(chunk_embedding)\n",
    "                elif isinstance(chunk_embedding, str):\n",
    "                    # Try parsing as JSON array\n",
    "                    import json\n",
    "                    try:\n",
    "                        chunk_embedding = np.array(json.loads(chunk_embedding))\n",
    "                    except:\n",
    "                        print(f\"âŒ Could not parse embedding for {chunk['chunk_heading']}\")\n",
    "                        continue\n",
    "                else:\n",
    "                    # Assume it's already a numpy array or compatible\n",
    "                    chunk_embedding = np.array(chunk_embedding)\n",
    "                \n",
    "                # Ensure query embedding is also numpy array\n",
    "                query_embedding_np = np.array(query_embedding)\n",
    "                \n",
    "                # Calculate cosine similarity (dot product of normalized vectors)\n",
    "                # For now just use dot product for simplicity\n",
    "                similarity = np.dot(query_embedding_np, chunk_embedding)\n",
    "                \n",
    "                similarities.append({\n",
    "                    'chunk': chunk,\n",
    "                    'similarity': float(similarity)  # Ensure it's a regular float\n",
    "                })\n",
    "        \n",
    "        # Sort by similarity\n",
    "        similarities.sort(key=lambda x: x['similarity'], reverse=True)\n",
    "        \n",
    "        print(f\"\\nğŸ¯ Top matches for '{query_text}':\")\n",
    "        for i, match in enumerate(similarities[:3]):\n",
    "            chunk = match['chunk']\n",
    "            score = match['similarity']\n",
    "            print(f\"  {i+1}. {chunk['chunk_heading']} (similarity: {score:.3f})\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in similarity search: {e}\")\n",
    "        import traceback\n",
    "        print(f\"Full traceback: {traceback.format_exc()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bfb5e9",
   "metadata": {},
   "source": [
    "### Embedding & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60827791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Initializing clients...\n",
      "ğŸ” Checking for existing chunks...\n",
      "  ğŸ“‹ Found existing: Leaves (index 1)\n",
      "  ğŸ“‹ Found existing: Health Benefits (index 0)\n",
      "  ğŸ“‹ Found existing: Perks (index 2)\n",
      "ğŸ“Š Found 3 existing chunks in database\n",
      "\n",
      "ğŸ“‚ Loading benefits data...\n",
      "ğŸ“Š Processing 3 chunks...\n",
      "\n",
      "ğŸ”„ Processing chunk 1: Health Benefits\n",
      "â­ï¸  Skipping - chunk already exists in database\n",
      "\n",
      "ğŸ”„ Processing chunk 2: Leaves\n",
      "â­ï¸  Skipping - chunk already exists in database\n",
      "\n",
      "ğŸ”„ Processing chunk 3: Perks\n",
      "â­ï¸  Skipping - chunk already exists in database\n",
      "\n",
      "ğŸ‰ Processing complete!\n",
      "   âœ… Newly embedded: 0 chunks\n",
      "   â­ï¸  Skipped existing: 3 chunks\n",
      "   ğŸ“Š Total chunks: 3\n",
      "\n",
      "ğŸ” Final database state...\n",
      "ğŸ“Š Total chunks in database: 3\n",
      "  - Leaves (ID: a64140ab...)\n",
      "  - Health Benefits (ID: fd4e01a2...)\n",
      "  - Perks (ID: d62a02fe...)\n"
     ]
    }
   ],
   "source": [
    "# Test the smart embedding function (will skip existing chunks)\n",
    "embed_benefits_chunks()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5de6eb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Testing similarity search for: 'health insurance plans'\n",
      "ğŸ§  Generating query embedding...\n",
      "ğŸ” Retrieving chunks from database...\n",
      "ğŸ“Š Retrieved 3 chunks for similarity comparison\n",
      "ğŸ” Debug - Embedding type: <class 'str'>\n",
      "ğŸ” Debug - Embedding preview: [-0.016314207,0.03778174,0.030891964,0.039434165,-0.038173843,-0.025262512,-0.018246705,-0.004253596...\n",
      "\n",
      "ğŸ¯ Top matches for 'health insurance plans':\n",
      "  1. Health Benefits (similarity: 0.489)\n",
      "  2. Leaves (similarity: 0.173)\n",
      "  3. Perks (similarity: 0.137)\n",
      "\n",
      "ğŸ” Testing similarity search for: 'vacation time off'\n",
      "ğŸ§  Generating query embedding...\n",
      "ğŸ” Retrieving chunks from database...\n",
      "ğŸ“Š Retrieved 3 chunks for similarity comparison\n",
      "ğŸ” Debug - Embedding type: <class 'str'>\n",
      "ğŸ” Debug - Embedding preview: [-0.016314207,0.03778174,0.030891964,0.039434165,-0.038173843,-0.025262512,-0.018246705,-0.004253596...\n",
      "\n",
      "ğŸ¯ Top matches for 'vacation time off':\n",
      "  1. Leaves (similarity: 0.407)\n",
      "  2. Perks (similarity: 0.270)\n",
      "  3. Health Benefits (similarity: 0.200)\n"
     ]
    }
   ],
   "source": [
    "# Test similarity search\n",
    "test_similarity_search(\"health insurance plans\")\n",
    "test_similarity_search(\"vacation time off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e65f1eb",
   "metadata": {},
   "source": [
    "## Embed Entire Contextual Benefits Doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787b6eba",
   "metadata": {},
   "source": [
    "## Multi-Document Embedding Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ebe626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_multiple_documents(document_files, table_name=\"faq_docs\"):\n",
    "    \"\"\"\n",
    "    Embed multiple JSON documents into Supabase table with duplicate checking\n",
    "    \n",
    "    Args:\n",
    "        document_files: List of file paths to JSON documents\n",
    "        table_name: Supabase table name to insert into\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize clients\n",
    "    print(\"ğŸ”§ Initializing clients...\")\n",
    "    openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
    "    \n",
    "    # Check what chunks already exist across all documents\n",
    "    print(\"ğŸ” Checking for existing chunks...\")\n",
    "    try:\n",
    "        existing_chunks = supabase.table(table_name).select(\"source_file, chunk_index, chunk_heading\").execute()\n",
    "        existing_set = set()\n",
    "        existing_by_file = {}\n",
    "        \n",
    "        for chunk in existing_chunks.data:\n",
    "            key = (chunk['source_file'], chunk['chunk_index'])\n",
    "            existing_set.add(key)\n",
    "            \n",
    "            # Track by file for reporting\n",
    "            file_name = chunk['source_file']\n",
    "            if file_name not in existing_by_file:\n",
    "                existing_by_file[file_name] = []\n",
    "            existing_by_file[file_name].append(chunk['chunk_heading'])\n",
    "        \n",
    "        print(f\"ğŸ“Š Found {len(existing_chunks.data)} existing chunks in database\")\n",
    "        for file_name, headings in existing_by_file.items():\n",
    "            print(f\"  ğŸ“‹ {file_name}: {len(headings)} chunks\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error checking existing chunks: {e}\")\n",
    "        existing_set = set()\n",
    "        existing_by_file = {}\n",
    "    \n",
    "    # Process each document file\n",
    "    total_processed = 0\n",
    "    total_skipped = 0\n",
    "    total_errors = 0\n",
    "    \n",
    "    for doc_file in document_files:\n",
    "        print(f\"\\nğŸ“‚ Processing document: {doc_file}\")\n",
    "        \n",
    "        # Load the document data\n",
    "        try:\n",
    "            with open(doc_file, \"r\") as f:\n",
    "                document_data = json.load(f)\n",
    "            print(f\"ğŸ“Š Loaded {len(document_data)} chunks from {doc_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error loading {doc_file}: {e}\")\n",
    "            total_errors += 1\n",
    "            continue\n",
    "        \n",
    "        # Track progress for this document\n",
    "        doc_processed = 0\n",
    "        doc_skipped = 0\n",
    "        doc_errors = 0\n",
    "        \n",
    "        # Process each chunk in the document\n",
    "        for i, chunk in enumerate(document_data):\n",
    "            source_file = doc_file.split('/')[-1]  # Get just the filename\n",
    "            chunk_key = (source_file, i)\n",
    "            \n",
    "            print(f\"\\n  ğŸ”„ Processing chunk {i+1}/{len(document_data)}: {chunk.get('chunk_heading', 'Untitled')}\")\n",
    "            \n",
    "            # Check if this chunk already exists\n",
    "            if chunk_key in existing_set:\n",
    "                print(f\"  â­ï¸  Skipping - chunk already exists in database\")\n",
    "                doc_skipped += 1\n",
    "                continue\n",
    "            \n",
    "            # Validate chunk structure\n",
    "            if 'text' not in chunk:\n",
    "                print(f\"  âŒ Skipping - chunk missing 'text' field\")\n",
    "                doc_errors += 1\n",
    "                continue\n",
    "            \n",
    "            # Prepare content for embedding\n",
    "            heading = chunk.get('chunk_heading', 'Untitled')\n",
    "            content = chunk['text']\n",
    "            embedding_content = f\"{heading}\\n\\n{content}\"\n",
    "            \n",
    "            # Generate embedding\n",
    "            print(f\"  ğŸ§  Generating embedding...\")\n",
    "            try:\n",
    "                response = openai_client.embeddings.create(\n",
    "                    model=\"text-embedding-3-small\",\n",
    "                    input=embedding_content\n",
    "                )\n",
    "                embedding = response.data[0].embedding\n",
    "                print(f\"  âœ… Generated embedding with {len(embedding)} dimensions\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  âŒ Error generating embedding: {e}\")\n",
    "                doc_errors += 1\n",
    "                continue\n",
    "            \n",
    "            # Prepare data for insertion\n",
    "            chunk_data = {\n",
    "                \"source_file\": source_file,\n",
    "                \"chunk_index\": i,\n",
    "                \"chunk_heading\": heading,\n",
    "                \"content\": content,\n",
    "                \"situational_context\": chunk.get(\"situational_context\", \"\"),\n",
    "                \"embedding\": embedding\n",
    "            }\n",
    "            \n",
    "            # Insert into Supabase\n",
    "            print(f\"  ğŸ’¾ Inserting chunk into Supabase...\")\n",
    "            try:\n",
    "                result = supabase.table(table_name).insert(chunk_data).execute()\n",
    "                print(f\"  âœ… Successfully inserted: {heading}\")\n",
    "                doc_processed += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  âŒ Error inserting into Supabase: {e}\")\n",
    "                doc_errors += 1\n",
    "                continue\n",
    "        \n",
    "        # Document summary\n",
    "        print(f\"\\nğŸ“‹ Document '{doc_file}' summary:\")\n",
    "        print(f\"   âœ… Newly embedded: {doc_processed} chunks\")\n",
    "        print(f\"   â­ï¸  Skipped existing: {doc_skipped} chunks\")\n",
    "        print(f\"   âŒ Errors: {doc_errors} chunks\")\n",
    "        \n",
    "        # Update totals\n",
    "        total_processed += doc_processed\n",
    "        total_skipped += doc_skipped\n",
    "        total_errors += doc_errors\n",
    "    \n",
    "    # Final summary\n",
    "    print(f\"\\nğŸ‰ Multi-document processing complete!\")\n",
    "    print(f\"   ğŸ“ Documents processed: {len(document_files)}\")\n",
    "    print(f\"   âœ… Total newly embedded: {total_processed} chunks\")\n",
    "    print(f\"   â­ï¸  Total skipped existing: {total_skipped} chunks\")\n",
    "    print(f\"   âŒ Total errors: {total_errors} chunks\")\n",
    "    \n",
    "    # Final database state\n",
    "    print(f\"\\nğŸ” Final database state...\")\n",
    "    try:\n",
    "        final_query = supabase.table(table_name).select(\"source_file, chunk_heading\").execute()\n",
    "        print(f\"ğŸ“Š Total chunks in '{table_name}' table: {len(final_query.data)}\")\n",
    "        \n",
    "        # Group by source file\n",
    "        by_file = {}\n",
    "        for chunk in final_query.data:\n",
    "            file_name = chunk['source_file']\n",
    "            if file_name not in by_file:\n",
    "                by_file[file_name] = []\n",
    "            by_file[file_name].append(chunk['chunk_heading'])\n",
    "        \n",
    "        for file_name, headings in by_file.items():\n",
    "            print(f\"  ğŸ“‹ {file_name}: {len(headings)} chunks\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error querying final state: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b862de",
   "metadata": {},
   "source": [
    "### Test Multi-Document Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22e3cea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage function\n",
    "def embed_all_available_documents():\n",
    "    \"\"\"\n",
    "    Embed all available documents in the data directory\n",
    "    \"\"\"\n",
    "    import os\n",
    "    \n",
    "    # List of documents to process\n",
    "    document_files = [\n",
    "        \"data/benefits_wellbeing_with_context.json\",\n",
    "        \"data/employee_handbook_with_context.json\"\n",
    "    ]\n",
    "    \n",
    "    # Filter to only existing files\n",
    "    existing_files = []\n",
    "    for file_path in document_files:\n",
    "        if os.path.exists(file_path):\n",
    "            existing_files.append(file_path)\n",
    "            print(f\"âœ… Found: {file_path}\")\n",
    "        else:\n",
    "            print(f\"âŒ Missing: {file_path}\")\n",
    "    \n",
    "    if not existing_files:\n",
    "        print(\"âŒ No document files found!\")\n",
    "        return\n",
    "    \n",
    "    # Embed all documents\n",
    "    embed_multiple_documents(existing_files, table_name=\"faq_docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fee032d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Found: data/benefits_wellbeing_with_context.json\n",
      "âœ… Found: data/employee_handbook_with_context.json\n",
      "ğŸ”§ Initializing clients...\n",
      "ğŸ” Checking for existing chunks...\n",
      "ğŸ“Š Found 5 existing chunks in database\n",
      "  ğŸ“‹ benefits_wellbeing_with_context.json: 5 chunks\n",
      "\n",
      "ğŸ“‚ Processing document: data/benefits_wellbeing_with_context.json\n",
      "ğŸ“Š Loaded 5 chunks from data/benefits_wellbeing_with_context.json\n",
      "\n",
      "  ğŸ”„ Processing chunk 1/5: Health Benefits\n",
      "  â­ï¸  Skipping - chunk already exists in database\n",
      "\n",
      "  ğŸ”„ Processing chunk 2/5: Leaves\n",
      "  â­ï¸  Skipping - chunk already exists in database\n",
      "\n",
      "  ğŸ”„ Processing chunk 3/5: Perks\n",
      "  â­ï¸  Skipping - chunk already exists in database\n",
      "\n",
      "  ğŸ”„ Processing chunk 4/5: 401k & Financial Benefits\n",
      "  â­ï¸  Skipping - chunk already exists in database\n",
      "\n",
      "  ğŸ”„ Processing chunk 5/5: Time Off &  Holidays\n",
      "  â­ï¸  Skipping - chunk already exists in database\n",
      "\n",
      "ğŸ“‹ Document 'data/benefits_wellbeing_with_context.json' summary:\n",
      "   âœ… Newly embedded: 0 chunks\n",
      "   â­ï¸  Skipped existing: 5 chunks\n",
      "   âŒ Errors: 0 chunks\n",
      "\n",
      "ğŸ“‚ Processing document: data/employee_handbook_with_context.json\n",
      "ğŸ“Š Loaded 77 chunks from data/employee_handbook_with_context.json\n",
      "\n",
      "  ğŸ”„ Processing chunk 1/77: For our team members working outside of New York State:\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: For our team members working outside of New York State:\n",
      "\n",
      "  ğŸ”„ Processing chunk 2/77: **Uniswap Principles | Uni-code**\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: **Uniswap Principles | Uni-code**\n",
      "\n",
      "  ğŸ”„ Processing chunk 3/77: Code of Ethics {#code-of-ethics}\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Code of Ethics {#code-of-ethics}\n",
      "\n",
      "  ğŸ”„ Processing chunk 4/77: \n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: \n",
      "\n",
      "  ğŸ”„ Processing chunk 5/77: Devices and Communications {#devices-and-communications}\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Devices and Communications {#devices-and-communications}\n",
      "\n",
      "  ğŸ”„ Processing chunk 6/77: \n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: \n",
      "\n",
      "  ğŸ”„ Processing chunk 7/77: \n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: \n",
      "\n",
      "  ğŸ”„ Processing chunk 8/77: Social Media Guidelines  {#social-media-guidelines}\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Social Media Guidelines  {#social-media-guidelines}\n",
      "\n",
      "  ğŸ”„ Processing chunk 9/77: \n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: \n",
      "\n",
      "  ğŸ”„ Processing chunk 10/77: Travel and Event Safety {#travel-and-event-safety}\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Travel and Event Safety {#travel-and-event-safety}\n",
      "\n",
      "  ğŸ”„ Processing chunk 11/77: Uniswap Labs takes reasonable measures to protect the physical safety of employees. We comply with safety standards in our New York office and will take reasonable measures to protect employees when we host events outside of our office.\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Uniswap Labs takes reasonable measures to protect the physical safety of employees. We comply with safety standards in our New York office and will take reasonable measures to protect employees when we host events outside of our office.\n",
      "\n",
      "  ğŸ”„ Processing chunk 12/77: That said, Uniswap Labs employees may participate in travel or other third-party events such as conferences, activities, and social gatherings that take place outside of our office. Such events are beyond the control of the company. Even though you may be with other employees or attending such an event in part because of your employment, you accept that you are responsible for yourself in locations and situations outside of the Uniswap Labs office.\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: That said, Uniswap Labs employees may participate in travel or other third-party events such as conferences, activities, and social gatherings that take place outside of our office. Such events are beyond the control of the company. Even though you may be with other employees or attending such an event in part because of your employment, you accept that you are responsible for yourself in locations and situations outside of the Uniswap Labs office.\n",
      "\n",
      "  ğŸ”„ Processing chunk 13/77: Please make sure you take appropriate precautions when participating in these kinds of travel and events and making related arrangements (e.g., transportation), especially when youâ€™re in any places that have had a history of safety concerns.\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Please make sure you take appropriate precautions when participating in these kinds of travel and events and making related arrangements (e.g., transportation), especially when youâ€™re in any places that have had a history of safety concerns.\n",
      "\n",
      "  ğŸ”„ Processing chunk 14/77: \n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: \n",
      "\n",
      "  ğŸ”„ Processing chunk 15/77: Employment Classifications\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Employment Classifications\n",
      "\n",
      "  ğŸ”„ Processing chunk 16/77: Zero Tolerance Harassment and Discrimination Policy  {#zero-tolerance-harassment-and-discrimination-policy}\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Zero Tolerance Harassment and Discrimination Policy  {#zero-tolerance-harassment-and-discrimination-policy}\n",
      "\n",
      "  ğŸ”„ Processing chunk 17/77: General Anti-Retaliation Policy\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: General Anti-Retaliation Policy\n",
      "\n",
      "  ğŸ”„ Processing chunk 18/77: Notice of Rights and Remedies Under New York Labor Law Section 203-E (New York State)\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Notice of Rights and Remedies Under New York Labor Law Section 203-E (New York State)\n",
      "\n",
      "  ğŸ”„ Processing chunk 19/77: \n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: \n",
      "\n",
      "  ğŸ”„ Processing chunk 20/77: Reasonable Accommodations:  Disability, Nursing Mothers and Religious  {#reasonable-accommodations:-disability,-nursing-mothers-and-religious}\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Reasonable Accommodations:  Disability, Nursing Mothers and Religious  {#reasonable-accommodations:-disability,-nursing-mothers-and-religious}\n",
      "\n",
      "  ğŸ”„ Processing chunk 21/77: Wage and Hours/Attendance {#wage-and-hours/attendance}\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Wage and Hours/Attendance {#wage-and-hours/attendance}\n",
      "\n",
      "  ğŸ”„ Processing chunk 22/77: Pay Period and Deductions {#pay-period-and-deductions}\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Pay Period and Deductions {#pay-period-and-deductions}\n",
      "\n",
      "  ğŸ”„ Processing chunk 23/77: Record Keeping {#record-keeping}\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Record Keeping {#record-keeping}\n",
      "\n",
      "  ğŸ”„ Processing chunk 24/77: Signatory Guidelines {#signatory-guidelines}\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Signatory Guidelines {#signatory-guidelines}\n",
      "\n",
      "  ğŸ”„ Processing chunk 25/77: \n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: \n",
      "\n",
      "  ğŸ”„ Processing chunk 26/77: Remote Work Guidelines {#remote-work-guidelines}\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Remote Work Guidelines {#remote-work-guidelines}\n",
      "\n",
      "  ğŸ”„ Processing chunk 27/77: Business Expenses and Travel {#business-expenses-and-travel}\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Business Expenses and Travel {#business-expenses-and-travel}\n",
      "\n",
      "  ğŸ”„ Processing chunk 28/77: Airline Travel\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Airline Travel\n",
      "\n",
      "  ğŸ”„ Processing chunk 29/77: Hotels/Rentals\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Hotels/Rentals\n",
      "\n",
      "  ğŸ”„ Processing chunk 30/77: Ground Transportation\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Ground Transportation\n",
      "\n",
      "  ğŸ”„ Processing chunk 31/77: \n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: \n",
      "\n",
      "  ğŸ”„ Processing chunk 32/77: Travel Meals\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Travel Meals\n",
      "\n",
      "  ğŸ”„ Processing chunk 33/77: Mileage Reimbursement\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Mileage Reimbursement\n",
      "\n",
      "  ğŸ”„ Processing chunk 34/77: Visas & Vaccinations\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Visas & Vaccinations\n",
      "\n",
      "  ğŸ”„ Processing chunk 35/77: Phones\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Phones\n",
      "\n",
      "  ğŸ”„ Processing chunk 36/77: Expense Types\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Expense Types\n",
      "\n",
      "  ğŸ”„ Processing chunk 37/77: Travel Expenses\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Travel Expenses\n",
      "\n",
      "  ğŸ”„ Processing chunk 38/77: Employee Benefits {#employee-benefits}\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Employee Benefits {#employee-benefits}\n",
      "\n",
      "  ğŸ”„ Processing chunk 39/77: Unlimited Paid Time Off (PTO) {#unlimited-paid-time-off-(pto)}\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Unlimited Paid Time Off (PTO) {#unlimited-paid-time-off-(pto)}\n",
      "\n",
      "  ğŸ”„ Processing chunk 40/77: Holidays {#holidays}\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Holidays {#holidays}\n",
      "\n",
      "  ğŸ”„ Processing chunk 41/77: Requesting PTO for Sick Leave Purposes {#requesting-pto-for-sick-leave-purposes}\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Requesting PTO for Sick Leave Purposes {#requesting-pto-for-sick-leave-purposes}\n",
      "\n",
      "  ğŸ”„ Processing chunk 42/77: Sick Leave Policy for team members Who Are NOT Eligible for PTO\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Sick Leave Policy for team members Who Are NOT Eligible for PTO\n",
      "\n",
      "  ğŸ”„ Processing chunk 43/77: Team members Working Outside of New York and California State\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Team members Working Outside of New York and California State\n",
      "\n",
      "  ğŸ”„ Processing chunk 44/77: A Note on the COVID-19 Pandemic\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: A Note on the COVID-19 Pandemic\n",
      "\n",
      "  ğŸ”„ Processing chunk 45/77: New York HERO Act  \\- Airborne Infectious Disease Exposure Prevention Plan\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: New York HERO Act  \\- Airborne Infectious Disease Exposure Prevention Plan\n",
      "\n",
      "  ğŸ”„ Processing chunk 46/77: \n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: \n",
      "\n",
      "  ğŸ”„ Processing chunk 47/77: Parental and Family Leave  {#parental-and-family-leave}\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Parental and Family Leave  {#parental-and-family-leave}\n",
      "\n",
      "  ğŸ”„ Processing chunk 48/77: Additional Leave of Absence Policies  {#additional-leave-of-absence-policies}\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Additional Leave of Absence Policies  {#additional-leave-of-absence-policies}\n",
      "\n",
      "  ğŸ”„ Processing chunk 49/77: Crime, Victim or Witness Leave\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Crime, Victim or Witness Leave\n",
      "\n",
      "  ğŸ”„ Processing chunk 50/77: COBRA  {#cobra}\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: COBRA  {#cobra}\n",
      "\n",
      "  ğŸ”„ Processing chunk 51/77: Conflicts of Interest  {#conflicts-of-interest}\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Conflicts of Interest  {#conflicts-of-interest}\n",
      "\n",
      "  ğŸ”„ Processing chunk 52/77: Relationships in the Workplace {#relationships-in-the-workplace}\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Relationships in the Workplace {#relationships-in-the-workplace}\n",
      "\n",
      "  ğŸ”„ Processing chunk 53/77: Candidate Referrals\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Candidate Referrals\n",
      "\n",
      "  ğŸ”„ Processing chunk 54/77: \n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: \n",
      "\n",
      "  ğŸ”„ Processing chunk 55/77: Hiring Family Members  {#hiring-family-members}\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Hiring Family Members  {#hiring-family-members}\n",
      "\n",
      "  ğŸ”„ Processing chunk 56/77: Workplace Violence and Substance Abuse {#workplace-violence-and-substance-abuse}\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Workplace Violence and Substance Abuse {#workplace-violence-and-substance-abuse}\n",
      "\n",
      "  ğŸ”„ Processing chunk 57/77: Workplace Violence\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Workplace Violence\n",
      "\n",
      "  ğŸ”„ Processing chunk 58/77: Uniswap Labs has a zero tolerance for acts of violence and threats of violence.  Without exception, acts and threats of violence are not permitted. All such acts and threats, even those made in apparent jest, will be taken seriously and will lead to appropriate discipline, up to and including termination.  Weapons, including firearms, are not permitted on Uniswap Labs premises.\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Uniswap Labs has a zero tolerance for acts of violence and threats of violence.  Without exception, acts and threats of violence are not permitted. All such acts and threats, even those made in apparent jest, will be taken seriously and will lead to appropriate discipline, up to and including termination.  Weapons, including firearms, are not permitted on Uniswap Labs premises.\n",
      "\n",
      "  ğŸ”„ Processing chunk 59/77: \n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: \n",
      "\n",
      "  ğŸ”„ Processing chunk 60/77: Substance Abuse\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Substance Abuse\n",
      "\n",
      "  ğŸ”„ Processing chunk 61/77: Other Prohibited Conduct\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Other Prohibited Conduct\n",
      "\n",
      "  ğŸ”„ Processing chunk 62/77: Compliance With Anti-Corruption and Anti-Money Laundering Laws\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Compliance With Anti-Corruption and Anti-Money Laundering Laws\n",
      "\n",
      "  ğŸ”„ Processing chunk 63/77: Under this Policy, neither the Company nor any employee or other person acting on the Companyâ€™s behalf may take any action in violation of, or fail to take any action consistent with and/or required by, this Policy or Anti-Corruption or AML Laws.  Violations of this Policy or applicable Anti-Corruption or AML Laws will be grounds for disciplinary action, up to and including termination.\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Under this Policy, neither the Company nor any employee or other person acting on the Companyâ€™s behalf may take any action in violation of, or fail to take any action consistent with and/or required by, this Policy or Anti-Corruption or AML Laws.  Violations of this Policy or applicable Anti-Corruption or AML Laws will be grounds for disciplinary action, up to and including termination.\n",
      "\n",
      "  ğŸ”„ Processing chunk 64/77: This Policy applies to all Company personnel, wherever located.  The Company also expects any third parties that act on the Companyâ€™s behalf, including agents and other intermediaries, to understand and fully comply with their obligations under Anti-Corruption and AML Laws. Failure to comply will be grounds for immediate termination of the business relationship with that third party.\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: This Policy applies to all Company personnel, wherever located.  The Company also expects any third parties that act on the Companyâ€™s behalf, including agents and other intermediaries, to understand and fully comply with their obligations under Anti-Corruption and AML Laws. Failure to comply will be grounds for immediate termination of the business relationship with that third party.\n",
      "\n",
      "  ğŸ”„ Processing chunk 65/77: 4.1       \tOverview\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: 4.1       \tOverview\n",
      "\n",
      "  ğŸ”„ Processing chunk 66/77: In relevant part, the FCPA prohibits the Company and its employees, agents, officers, directors, and shareholders from offering, paying, promising to pay, or authorizing the payment of any money, or offering, gifting, promising to gift, or authorizing the giving of *anything of value* to any Foreign Official, any foreign political party or official thereof, any candidate for foreign political office, or any other person, while knowing that all or a portion of such money or thing of value will be offered, given, or promised, directly or indirectly, to any such person for the purpose of:\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: In relevant part, the FCPA prohibits the Company and its employees, agents, officers, directors, and shareholders from offering, paying, promising to pay, or authorizing the payment of any money, or offering, gifting, promising to gift, or authorizing the giving of *anything of value* to any Foreign Official, any foreign political party or official thereof, any candidate for foreign political office, or any other person, while knowing that all or a portion of such money or thing of value will be offered, given, or promised, directly or indirectly, to any such person for the purpose of:\n",
      "\n",
      "  ğŸ”„ Processing chunk 67/77: 4.2       \tForeign Officials\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: 4.2       \tForeign Officials\n",
      "\n",
      "  ğŸ”„ Processing chunk 68/77: 4.3       \tAnything of Value\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: 4.3       \tAnything of Value\n",
      "\n",
      "  ğŸ”„ Processing chunk 69/77: 4.4       \tThird Parties and Knowledge\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: 4.4       \tThird Parties and Knowledge\n",
      "\n",
      "  ğŸ”„ Processing chunk 70/77: 4.5       \tHow the Company Complies with Anti-Corruption Laws\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: 4.5       \tHow the Company Complies with Anti-Corruption Laws\n",
      "\n",
      "  ğŸ”„ Processing chunk 71/77: 6.1       \tReporting Obligations\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: 6.1       \tReporting Obligations\n",
      "\n",
      "  ğŸ”„ Processing chunk 72/77: Under no circumstances shall the reporting of any such information or possible violation serve as a basis for any retaliatory actions to be taken against any employee making the report.\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Under no circumstances shall the reporting of any such information or possible violation serve as a basis for any retaliatory actions to be taken against any employee making the report.\n",
      "\n",
      "  ğŸ”„ Processing chunk 73/77: 6.2       \tTraining Obligations\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: 6.2       \tTraining Obligations\n",
      "\n",
      "  ğŸ”„ Processing chunk 74/77: 6.3       \tThird-Party Due Diligence Obligations\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: 6.3       \tThird-Party Due Diligence Obligations\n",
      "\n",
      "  ğŸ”„ Processing chunk 75/77: Failure to comply with Anti-Corruption or AML Laws may result in serious civil, criminal, and administrative penalties.  Individuals may also be subject to severe penalties, including substantial fines and, in the case of knowing violations, imprisonment.  The Company will not tolerate violations of law or this Policy by personnel or any third party acting on the Companyâ€™s behalf.  Violations will be grounds for disciplinary action, up to and including immediate termination.\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Failure to comply with Anti-Corruption or AML Laws may result in serious civil, criminal, and administrative penalties.  Individuals may also be subject to severe penalties, including substantial fines and, in the case of knowing violations, imprisonment.  The Company will not tolerate violations of law or this Policy by personnel or any third party acting on the Companyâ€™s behalf.  Violations will be grounds for disciplinary action, up to and including immediate termination.\n",
      "\n",
      "  ğŸ”„ Processing chunk 76/77: OFAC Sanctions and Trade Compliance Program\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: OFAC Sanctions and Trade Compliance Program\n",
      "\n",
      "  ğŸ”„ Processing chunk 77/77: Conflict Resolution/Open Door Policy {#conflict-resolution/open-door-policy}\n",
      "  ğŸ§  Generating embedding...\n",
      "  âœ… Generated embedding with 1536 dimensions\n",
      "  ğŸ’¾ Inserting chunk into Supabase...\n",
      "  âœ… Successfully inserted: Conflict Resolution/Open Door Policy {#conflict-resolution/open-door-policy}\n",
      "\n",
      "ğŸ“‹ Document 'data/employee_handbook_with_context.json' summary:\n",
      "   âœ… Newly embedded: 77 chunks\n",
      "   â­ï¸  Skipped existing: 0 chunks\n",
      "   âŒ Errors: 0 chunks\n",
      "\n",
      "ğŸ‰ Multi-document processing complete!\n",
      "   ğŸ“ Documents processed: 2\n",
      "   âœ… Total newly embedded: 77 chunks\n",
      "   â­ï¸  Total skipped existing: 5 chunks\n",
      "   âŒ Total errors: 0 chunks\n",
      "\n",
      "ğŸ” Final database state...\n",
      "ğŸ“Š Total chunks in 'faq_docs' table: 82\n",
      "  ğŸ“‹ benefits_wellbeing_with_context.json: 5 chunks\n",
      "  ğŸ“‹ employee_handbook_with_context.json: 77 chunks\n"
     ]
    }
   ],
   "source": [
    "# Doing the embeddings\n",
    "embed_all_available_documents()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0741f7bb",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "266e7399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_all_benefits_chunks():\n",
    "    \"\"\"\n",
    "    Embed all chunks from benefits_wellbeing_with_context.json \n",
    "    into Supabase faq_docs table (only if they don't already exist)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize clients\n",
    "    print(\"Initializing clients...\")\n",
    "    openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
    "    \n",
    "    # Check what chunks already exist\n",
    "    print(\"Checking for existing chunks...\")\n",
    "    try:\n",
    "        existing_chunks = supabase.table(\"faq_docs\").select(\"source_file, chunk_index, chunk_heading\").execute()\n",
    "        existing_set = set()\n",
    "        for chunk in existing_chunks.data:\n",
    "            key = (chunk['source_file'], chunk['chunk_index'])\n",
    "            existing_set.add(key)\n",
    "            print(f\"  ğŸ“‹ Found existing: {chunk['chunk_heading']} (index {chunk['chunk_index']})\")\n",
    "        \n",
    "        print(f\"ğŸ“Š Found {len(existing_chunks.data)} existing chunks in database\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error checking existing chunks: {e}\")\n",
    "        existing_set = set()\n",
    "    \n",
    "    # Load the benefits data\n",
    "    print(\"\\nLoading benefits data...\")\n",
    "    with open(\"data/benefits_wellbeing_with_context.json\", \"r\") as f:\n",
    "        benefits_data = json.load(f)\n",
    "\n",
    "    print(f\"ğŸ“Š Processing {len(benefits_data)} chunks...\")\n",
    "    \n",
    "    # Track what we actually process\n",
    "    processed_count = 0\n",
    "    skipped_count = 0\n",
    "    \n",
    "    # Process each chunk\n",
    "    for i, chunk in enumerate(benefits_data):\n",
    "        source_file = \"benefits_wellbeing_with_context.json\"\n",
    "        chunk_key = (source_file, i)\n",
    "        \n",
    "        print(f\"\\nProcessing chunk {i+1}: {chunk['chunk_heading']}\")\n",
    "        \n",
    "        # Check if this chunk already exists\n",
    "        if chunk_key in existing_set:\n",
    "            print(f\"Skipping - chunk already exists in database\")\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "        \n",
    "        # Prepare content for embedding (combine heading + text for better context)\n",
    "        embedding_content = f\"{chunk['chunk_heading']}\\n\\n{chunk['text']}\"\n",
    "        \n",
    "        # Generate embedding\n",
    "        print(f\"Generating embedding for '{chunk['chunk_heading']}'...\")\n",
    "        try:\n",
    "            response = openai_client.embeddings.create(\n",
    "                model=\"text-embedding-3-small\",\n",
    "                input=embedding_content\n",
    "            )\n",
    "            embedding = response.data[0].embedding\n",
    "            print(f\"Embeddings with: {len(embedding)} dimensions\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error generating embedding: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Prepare data for insertion\n",
    "        chunk_data = {\n",
    "            \"source_file\": source_file,\n",
    "            \"chunk_index\": i,\n",
    "            \"chunk_heading\": chunk[\"chunk_heading\"],\n",
    "            \"content\": chunk[\"text\"],\n",
    "            \"situational_context\": chunk[\"situational_context\"],\n",
    "            \"embedding\": embedding\n",
    "        }\n",
    "        \n",
    "        # Insert into Supabase\n",
    "        print(f\"ğŸ’¾ Inserting chunk into Supabase...\")\n",
    "        try:\n",
    "            result = supabase.table(\"faq_docs\").insert(chunk_data).execute()\n",
    "            print(f\"âœ… Successfully inserted chunk: {chunk['chunk_heading']}\")\n",
    "            processed_count += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error inserting into Supabase: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\nğŸ‰ Processing complete!\")\n",
    "    print(f\"   âœ… Newly embedded: {processed_count} chunks\")\n",
    "    print(f\"   â­ï¸  Skipped existing: {skipped_count} chunks\")\n",
    "    print(f\"   ğŸ“Š Total chunks: {processed_count + skipped_count}\")\n",
    "    \n",
    "    # Test a simple query\n",
    "    print(\"\\nğŸ” Final database state...\")\n",
    "    try:\n",
    "        test_query = supabase.table(\"faq_docs\").select(\"*\").execute()\n",
    "        print(f\"ğŸ“Š Total chunks in database: {len(test_query.data)}\")\n",
    "        for chunk in test_query.data:\n",
    "            print(f\"  - {chunk['chunk_heading']} (ID: {chunk['id'][:8]}...)\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error testing retrieval: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fa32042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing clients...\n",
      "Checking for existing chunks...\n",
      "ğŸ“Š Found 0 existing chunks in database\n",
      "\n",
      "Loading benefits data...\n",
      "ğŸ“Š Processing 5 chunks...\n",
      "\n",
      "Processing chunk 1: Health Benefits\n",
      "Generating embedding for 'Health Benefits'...\n",
      "Embeddings with: 1536 dimensions\n",
      "ğŸ’¾ Inserting chunk into Supabase...\n",
      "âœ… Successfully inserted chunk: Health Benefits\n",
      "\n",
      "Processing chunk 2: Leaves\n",
      "Generating embedding for 'Leaves'...\n",
      "Embeddings with: 1536 dimensions\n",
      "ğŸ’¾ Inserting chunk into Supabase...\n",
      "âœ… Successfully inserted chunk: Leaves\n",
      "\n",
      "Processing chunk 3: Perks\n",
      "Generating embedding for 'Perks'...\n",
      "Embeddings with: 1536 dimensions\n",
      "ğŸ’¾ Inserting chunk into Supabase...\n",
      "âœ… Successfully inserted chunk: Perks\n",
      "\n",
      "Processing chunk 4: 401k & Financial Benefits\n",
      "Generating embedding for '401k & Financial Benefits'...\n",
      "Embeddings with: 1536 dimensions\n",
      "ğŸ’¾ Inserting chunk into Supabase...\n",
      "âœ… Successfully inserted chunk: 401k & Financial Benefits\n",
      "\n",
      "Processing chunk 5: Time Off &  Holidays\n",
      "Generating embedding for 'Time Off &  Holidays'...\n",
      "Embeddings with: 1536 dimensions\n",
      "ğŸ’¾ Inserting chunk into Supabase...\n",
      "âœ… Successfully inserted chunk: Time Off &  Holidays\n",
      "\n",
      "ğŸ‰ Processing complete!\n",
      "   âœ… Newly embedded: 5 chunks\n",
      "   â­ï¸  Skipped existing: 0 chunks\n",
      "   ğŸ“Š Total chunks: 5\n",
      "\n",
      "ğŸ” Final database state...\n",
      "ğŸ“Š Total chunks in database: 5\n",
      "  - Health Benefits (ID: a8114f3a...)\n",
      "  - Leaves (ID: ed5d0ed1...)\n",
      "  - Perks (ID: 825fce90...)\n",
      "  - 401k & Financial Benefits (ID: f505b922...)\n",
      "  - Time Off &  Holidays (ID: 997a8210...)\n"
     ]
    }
   ],
   "source": [
    "# Embed all chunks\n",
    "embed_all_benefits_chunks()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
