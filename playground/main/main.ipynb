{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Contextual RAG System - Clean Demo\n",
        "\n",
        "This notebook demonstrates the modular contextual retrieval system with three approaches:\n",
        "\n",
        "- **Basic RAG**: Standard document chunking and embedding\n",
        "- **Contextual RAG**: Enhanced embeddings with situational context  \n",
        "- **Combined RAG**: Multi-document search with source attribution\n",
        "\n",
        "All functionality is cleanly separated into modules - this notebook focuses on **demonstration and testing**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Setup & Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ All modules loaded successfully\n",
            "üìÅ Data directory: ../data\n"
          ]
        }
      ],
      "source": [
        "# Import the clean modular components\n",
        "import json\n",
        "import textwrap\n",
        "from vector_db import VectorDB, ContextualVectorDB\n",
        "from rag_operations import (\n",
        "    answer_query_base, answer_query_contextual, answer_query_combined\n",
        ")\n",
        "from data_utils import (\n",
        "    transform_data_for_vectordb, create_contextual_dataset, \n",
        "    create_combined_dataset\n",
        ")\n",
        "import config\n",
        "\n",
        "from config import OPENAI_API_KEY, ANTHROPIC_API_KEY, COHERE_API_KEY, GREENHOUSE_API_KEY, ANSWER_MODEL\n",
        "\n",
        "def wrap_text(text: str, width: int = 90) -> str:\n",
        "    \"\"\"Wrap text to specified width while preserving paragraph breaks.\"\"\"\n",
        "    if not text:\n",
        "        return text\n",
        "    \n",
        "    # Split by double newlines to preserve paragraph breaks\n",
        "    paragraphs = text.split('\\n\\n')\n",
        "    wrapped_paragraphs = []\n",
        "    \n",
        "    for paragraph in paragraphs:\n",
        "        # Remove single newlines within paragraphs and wrap\n",
        "        cleaned_paragraph = paragraph.replace('\\n', ' ').strip()\n",
        "        if cleaned_paragraph:\n",
        "            wrapped = textwrap.fill(cleaned_paragraph, width=width)\n",
        "            wrapped_paragraphs.append(wrapped)\n",
        "    \n",
        "    return '\\n\\n'.join(wrapped_paragraphs)\n",
        "\n",
        "print(\"‚úÖ All modules loaded successfully\")\n",
        "print(f\"üìÅ Data directory: {config.DATA_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Basic RAG Demo\n",
        "\n",
        "Standard document chunking and embedding approach.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìñ Loading employee handbook data...\n",
            "Loading vector database from disk.\n",
            "‚úÖ Loaded 77 chunks into basic VectorDB\n"
          ]
        }
      ],
      "source": [
        "# Load employee handbook data\n",
        "print(\"üìñ Loading employee handbook data...\")\n",
        "\n",
        "with open(config.EMPLOYEE_HANDBOOK_PATH, 'r') as f:\n",
        "    employee_handbook_raw = json.load(f)\n",
        "\n",
        "# Transform data for VectorDB\n",
        "employee_handbook = transform_data_for_vectordb(employee_handbook_raw, \"employee_handbook\")\n",
        "\n",
        "# Initialize and load VectorDB\n",
        "basic_db = VectorDB(\"employee_handbook\")\n",
        "basic_db.load_data(employee_handbook)\n",
        "\n",
        "print(f\"‚úÖ Loaded {len(employee_handbook[0]['chunks'])} chunks into basic VectorDB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Query: What are Uniswap's core values?\n",
            "============================================================\n",
            "üìù Basic RAG Answer:\n",
            "Uniswap's core values are articulated through their operating principles called \"Unicode,\"\n",
            "which serve as daily guideposts for how they interact with each other, users, and their\n",
            "community.\n",
            "\n",
            "**People First** represents their belief that easy, safe, fair value transfer on the\n",
            "internet can improve people's lives. Access, security and experience is the center of\n",
            "everything they do. By pursuing decentralization, interoperability, and durability they\n",
            "align with their users over the long-term. Internally, people are their greatest asset,\n",
            "and they strive for an environment where everyone can make an incredible impact. They\n",
            "share direct, kind feedback so they can improve. When advocating for an idea, technical\n",
            "tradeoff, or business goal, they start with why ‚Äî why it's better for their user and\n",
            "company.\n",
            "\n",
            "**Simple** reflects their craft of keeping things simple. In a complex field, they create\n",
            "clarity and simplicity. They write and build in human terms, understood by everyone. This\n",
            "shows up in the design and language of their user experience, across their code, and in\n",
            "how they speak to the world and each other. They are deliberate in the words and images\n",
            "they use.\n",
            "\n",
            "**Pink** demonstrates their love of pink, both conceptually and in real life. Disrupting\n",
            "the status quo is fun. They hold each other accountable to do serious work without taking\n",
            "themselves too seriously. They love unicorns and bring whimsy into their experiments and\n",
            "day-to-day work. The people-first, internet-native financial system they're building\n",
            "welcomes anyone.\n",
            "\n",
            "**Push Through Ambiguity Together** acknowledges that startup life can be ambiguous,\n",
            "especially at the frontier. They are at peace with uncertainty and push through\n",
            "resistance. They show up ready to explore new ideas with conviction that their mission is\n",
            "worth it. When things get hard, they stay on the same team. They create scalable solutions\n",
            "to make things less ambiguous in pursuit of their mission. They don't assume shared\n",
            "knowledge or beliefs across their team or users, and seek to understand others' \"why.\"\n",
            "When they don't agree with something, they assume positive intent and default to trust.\n",
            "\n",
            "**Build to last, iterate fast** means they see through the clouds of today into what's\n",
            "possible tomorrow. They don't fall prey to short-term thinking or get distracted by\n",
            "narratives and prices. They aim to move fast, learn from their mistakes, and ship when\n",
            "it's right. Where their opinions bring safety, simplicity, and new choices in the best\n",
            "interest of their users, they express them. This long-term view is a big part of why they\n",
            "are a beloved brand, which they must protect.\n",
            "\n",
            "Double-check with Julian or Megan for any of this information!\n"
          ]
        }
      ],
      "source": [
        "# Test basic RAG with text wrapping\n",
        "test_query = \"What are Uniswap's core values?\"\n",
        "\n",
        "print(f\"üîç Query: {test_query}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "answer = answer_query_base(test_query, basic_db)\n",
        "print(f\"üìù Basic RAG Answer:\\n{wrap_text(answer)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Contextual RAG Demo\n",
        "\n",
        "Enhanced embeddings with situational context for better retrieval accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìñ Loading contextual employee handbook database...\n",
            "‚úÖ Contextual VectorDB loaded successfully\n"
          ]
        }
      ],
      "source": [
        "# Load contextual dataset (pre-computed contextual information)\n",
        "print(\"üìñ Loading contextual employee handbook database...\")\n",
        "\n",
        "# This loads pre-created contextual embeddings\n",
        "contextual_db = ContextualVectorDB(\"employee_handbook_contextual\")\n",
        "contextual_db.load_db()  # Load from existing pickle file\n",
        "\n",
        "if contextual_db:\n",
        "    print(\"‚úÖ Contextual VectorDB loaded successfully\")\n",
        "else: print(\"what\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Query: Do we have any work from home benefits\n",
            "============================================================\n",
            "üß† Contextual RAG Answer:\n",
            "Uniswap Labs offers several work from home benefits for remote team members:\n",
            "\n",
            "**Home Office Setup Reimbursement**: The company reimburses up to $2,000 USD to cover the\n",
            "purchase of office supplies, productivity items, and anything else you might need to get\n",
            "your home office set up.\n",
            "\n",
            "**Coworking Space Allowance**: If you prefer to work from a co-working space instead of\n",
            "home, Uniswap Labs reimburses the cost up to $500 USD per month.\n",
            "\n",
            "**Flexible Remote Work Policy**: Remote working allows team members to work at home, on\n",
            "the road, or in a satellite location for all or part of their workweek, whenever you\n",
            "choose, unless otherwise decided upon for your role. The company considers telecommuting\n",
            "to be a viable, flexible work option and doesn't require anyone to come into the office if\n",
            "their preference is for remote working.\n",
            "\n",
            "**Equipment Provision**: All team members receive a company-issued computer to do their\n",
            "job, which supports remote work capabilities.\n",
            "\n",
            "The remote work arrangement can be informal (such as working from home for a short-term\n",
            "project or during business travel) or formal with a set schedule of working away from the\n",
            "office. While remote work is fully supported, the company encourages team members to visit\n",
            "the NYC office when possible, especially new hires for a week in the first month, to\n",
            "accelerate relationship building and experience the company culture firsthand.\n",
            "\n",
            "Double-check with Julian or Megan for any of this information!\n",
            "\n",
            "============================================================\n",
            "üîç Retrieved Chunks (for transparency):\n",
            "\n",
            "üìÑ Chunk 1 (Similarity: 0.510)\n",
            "   Section: Employee Benefits {#employee-benefits}\n",
            "   Context: This section on Employee Benefits is part of the \"How We Take Care Of You\" section of Uniswap's Empl...\n",
            "\n",
            "üìÑ Chunk 2 (Similarity: 0.446)\n",
            "   Section: Remote Work Guidelines {#remote-work-guidelines}\n",
            "   Context: This section on Remote Work Guidelines is part of the \"How We Work\" section of Uniswap's Employee Ha...\n",
            "\n",
            "üìÑ Chunk 3 (Similarity: 0.423)\n",
            "   Section: Team members Working Outside of New York and California State\n",
            "   Context: This section on team members working outside of New York and California is part of Uniswap's broader...\n"
          ]
        }
      ],
      "source": [
        "# Test contextual RAG with text wrapping\n",
        "test_query = \"Do we have any work from home benefits\"\n",
        "\n",
        "print(f\"üîç Query: {test_query}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "answer = answer_query_contextual(test_query, contextual_db)\n",
        "print(f\"üß† Contextual RAG Answer:\\n{wrap_text(answer)}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üîç Retrieved Chunks (for transparency):\")\n",
        "results = contextual_db.search(test_query, k=3)\n",
        "for i, result in enumerate(results, 1):\n",
        "    metadata = result['metadata']\n",
        "    print(f\"\\nüìÑ Chunk {i} (Similarity: {result['similarity']:.3f})\")\n",
        "    print(f\"   Section: {metadata.get('heading', 'N/A')}\")\n",
        "    context_preview = metadata.get('contextual_content', 'N/A')[:100]\n",
        "    print(f\"   Context: {context_preview}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. Interactive Testing\n",
        "\n",
        "Test your own queries with the clean RAG system. All text is wrapped at 90 characters for easy reading.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Query: How much vacation time do employees get?\n",
            "============================================================\n",
            "\n",
            "üß† Contextual RAG:\n",
            "Uniswap Labs provides Unlimited Paid Time Off (PTO) for eligible employees, meaning there\n",
            "is no maximum number of days off you can reasonably be approved to take, though time off\n",
            "should be taken in a way that is not disruptive to the business. The team historically\n",
            "averages around 4 weeks per year as the norm.\n",
            "\n",
            "PTO includes vacation, sick leave, bereavement leave, birthday reprieve, and any other\n",
            "time you may just need a break. Additionally, Uniswap has an annual end of year break with\n",
            "dates specified in the current year's holiday schedule.\n",
            "\n",
            "All regular full-time team members are eligible for PTO. However, temporary team members\n",
            "and regular part-time team members scheduled to work less than 20 hours per week are not\n",
            "eligible for PTO, though they are provided with sick time if required by applicable state\n",
            "or city law.\n",
            "\n",
            "For planned absences like vacation, you should request PTO from your manager and record it\n",
            "using the PTO by Deel app in Slack as far in advance as possible. Generally, one week's\n",
            "notice for your manager for every day you're taking off is the minimum, with more notice\n",
            "being better.\n",
            "\n",
            "PTO is not intended for extended personal leaves longer than two consecutive weeks - for\n",
            "such situations, you should speak to your manager or People team. Since PTO is unlimited\n",
            "and not accrued, there is no pay-out of PTO upon separation from employment except where\n",
            "required by law.\n",
            "\n",
            "Uniswap Labs will generally grant reasonable PTO requests when possible, considering\n",
            "business needs, but reserves the right to deny requests. Approval may not be given under\n",
            "certain circumstances, such as when an employee is on a performance improvement plan or\n",
            "has given notice of intent to leave.\n",
            "\n",
            "Double-check with Julian or Megan for any of this information!\n"
          ]
        }
      ],
      "source": [
        "# Interactive query testing function with text wrapping\n",
        "def test_query(query: str, approach: str = \"all\"):\n",
        "    \"\"\"Test a query with specified RAG approach(es). All text wrapped at 90 characters.\"\"\"\n",
        "    print(f\"üîç Query: {query}\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    if approach in [\"basic\", \"all\"]:\n",
        "        print(\"\\nüìù Basic RAG:\")\n",
        "        answer = answer_query_base(query, basic_db)\n",
        "        print(wrap_text(answer))\n",
        "    \n",
        "    if approach in [\"contextual\", \"all\"]:\n",
        "        print(\"\\nüß† Contextual RAG:\")\n",
        "        answer = answer_query_contextual(query, contextual_db)\n",
        "        print(wrap_text(answer))\n",
        "\n",
        "# Example usage - try your own queries!\n",
        "test_query(\"How much vacation time do employees get?\", \"contextual\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Summary\n",
        "\n",
        "This clean implementation demonstrates:\n",
        "\n",
        "‚úÖ **Modular Architecture**: All functionality separated into proper modules  \n",
        "‚úÖ **Two Main RAG Approaches**: Basic and Contextual retrieval  \n",
        "‚úÖ **Easy Testing**: Simple functions to test and compare approaches  \n",
        "‚úÖ **Clean Interface**: No cluttered inline functions or redundant code  \n",
        "‚úÖ **Error Handling**: Graceful fallbacks built into the modules  \n",
        "‚úÖ **Text Wrapping**: All answers wrapped at 90 characters for easy reading\n",
        "\n",
        "### Next Steps:\n",
        "- Test with your own queries using `test_query()`\n",
        "- Compare basic vs contextual retrieval performance\n",
        "- Explore the modular codebase in the separate `.py` files\n",
        "- Ready for production deployment or multi-agent expansion\n",
        "\n",
        "### Module Structure:\n",
        "- `vector_db.py` - VectorDB and ContextualVectorDB classes\n",
        "- `rag_operations.py` - RAG pipeline functions  \n",
        "- `data_utils.py` - Data transformation utilities\n",
        "- `config.py` - Configuration and API keys\n",
        "- `prompts.py` - System prompt templates\n",
        "\n",
        "### Text Wrapping:\n",
        "All answers are now wrapped at 90 characters with preserved paragraph breaks for optimal readability!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìñ Loading job descriptions data...\n",
            "‚úÖ Loaded 944 chunks into job descriptions VectorDB\n"
          ]
        }
      ],
      "source": [
        "# Load job descriptions data\n",
        "print(\"üìñ Loading job descriptions data...\")\n",
        "\n",
        "import re\n",
        "from vector_db import VectorDB, ContextualVectorDB\n",
        "\n",
        "def extract_job_info(content):\n",
        "    \"\"\"Extract job title and department from content.\"\"\"\n",
        "    title_match = re.search(r\"Job Title:\\s*(.+)\", content)\n",
        "    dept_match = re.search(r\"Department:\\s*(.+)\", content)\n",
        "    \n",
        "    job_title = title_match.group(1).strip() if title_match else \"Unknown\"\n",
        "    department = dept_match.group(1).strip() if dept_match else \"Unknown\"\n",
        "    \n",
        "    return job_title, department\n",
        "\n",
        "# Initialize and load VectorDB\n",
        "job_db = VectorDB(\"job_descriptions\")\n",
        "job_db.load_db()\n",
        "\n",
        "print(f\"‚úÖ Loaded {len(job_db.embeddings)} chunks into job descriptions VectorDB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîç Search results for 'Legal':\n",
            "  1. Legal Intern (Legal & Policy) - similarity: 0.374\n",
            "  2. Legal Counsel (Customer Experience) - similarity: 0.353\n",
            "  3. Commercial Contract Attorney (Legal & Policy) - similarity: 0.349\n",
            "  4. Assistant General Counsel, Product (Legal & Policy) - similarity: 0.344\n",
            "  5. Commercial Contract Attorney (Legal & Policy) - similarity: 0.341\n",
            "  6. Legal Counsel (Customer Experience) - similarity: 0.341\n",
            "  7. Legal Intern (Legal & Policy) - similarity: 0.340\n",
            "  8. Accounting Manager (Legal & Policy) - similarity: 0.339\n",
            "  9. Legal Program Manager (Legal & Policy) - similarity: 0.337\n",
            "  10. Legal Intern (Legal & Policy) - similarity: 0.334\n",
            "  11. Assistant General Counsel, Product (Legal & Policy) - similarity: 0.333\n",
            "  12. Senior Policy Associate (Legal & Policy) - similarity: 0.332\n",
            "  13. Associate General Counsel (Legal & Policy) - similarity: 0.331\n",
            "  14. Head of US Policy (Legal & Policy) - similarity: 0.327\n",
            "  15. Senior Counsel (Legal & Policy) - similarity: 0.327\n"
          ]
        }
      ],
      "source": [
        "# Test search\n",
        "query = \"Legal\"\n",
        "results = job_db.search(query, k=15)\n",
        "\n",
        "print(f\"\\nüîç Search results for '{query}':\")\n",
        "for i, result in enumerate(results[:15], 1):\n",
        "    content = result['metadata']['content']\n",
        "    job_title, department = extract_job_info(content)\n",
        "    similarity = result['similarity']\n",
        "    print(f\"  {i}. {job_title} ({department}) - similarity: {similarity:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Loaded 944 chunks into contextual job descriptions VectorDB\n"
          ]
        }
      ],
      "source": [
        "# For contextual embeddings:\n",
        "contextual_db = ContextualVectorDB(\"job_descriptions_contextual\")\n",
        "contextual_db.load_db()\n",
        "print(f\"‚úÖ Loaded {len(contextual_db.embeddings)} chunks into contextual job descriptions VectorDB\")\n",
        "\n",
        "# Your databases are now ready for search:\n",
        "# job_db.search(\"your query\", k=5)\n",
        "# contextual_db.search(\"your query\", k=5) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîç Search results for 'Engineering manager':\n"
          ]
        }
      ],
      "source": [
        "query = \"Engineering manager\"\n",
        "results = contextual_db.search(query, k=5)\n",
        "\n",
        "print(f\"\\nüîç Search results for '{query}':\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Function declaration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from typing import List, Dict, Any\n",
        "from pathlib import Path\n",
        "\n",
        "from vector_db import VectorDB \n",
        "from config import OPENAI_API_KEY\n",
        "\n",
        "\"\"\"\n",
        "============================================================================================\n",
        "Transform jobs for vector database\n",
        "============================================================================================\n",
        "\"\"\"\n",
        "def transform_jobs_for_vectordb(jobs_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
        "    doc = {\n",
        "        \"doc_id\": \"all_jobs\",\n",
        "        \"original_uuid\": \"all_jobs_uuid\",\n",
        "        \"chunks\": []\n",
        "    }\n",
        "    \n",
        "    for i, job in enumerate(jobs_data):\n",
        "        full_content = create_full_job_text(job)\n",
        "        doc[\"chunks\"].append({\n",
        "            \"chunk_id\": job['job_id'],\n",
        "            \"original_index\": i,\n",
        "            \"content\": full_content,\n",
        "            \"job_id\": job['job_id'],\n",
        "            \"job_title\": job['title'],\n",
        "            \"department\": job['department']\n",
        "        })\n",
        "    \n",
        "    return [doc]\n",
        "\n",
        "\"\"\"\n",
        "============================================================================================\n",
        "Create full job text\n",
        "============================================================================================\n",
        "\"\"\"\n",
        "def create_full_job_text(job: Dict[str, Any]) -> str:\n",
        "    \"\"\"Create a comprehensive text representation of a job.\"\"\"\n",
        "    \n",
        "    sections = []\n",
        "    \n",
        "    # Header\n",
        "    sections.append(f\"Job Title: {job['title']}\")\n",
        "    sections.append(f\"Department: {job['department']}\")\n",
        "    \n",
        "    # Metadata\n",
        "    metadata = job.get('metadata', {})\n",
        "    if metadata.get('seniority'):\n",
        "        sections.append(f\"Seniority Level: {metadata['seniority']}\")\n",
        "    if metadata.get('skills'):\n",
        "        sections.append(f\"Skills: {', '.join(metadata['skills'])}\")\n",
        "    \n",
        "    sections.append(\"\")  # Empty line\n",
        "    \n",
        "    # Introduction\n",
        "    if job['sections'].get('intro'):\n",
        "        sections.append(\"Job Description:\")\n",
        "        sections.append(job['sections']['intro'])\n",
        "        sections.append(\"\")\n",
        "    \n",
        "    # Responsibilities\n",
        "    if job['sections'].get('responsibilities'):\n",
        "        sections.append(\"Key Responsibilities:\")\n",
        "        for resp in job['sections']['responsibilities']:\n",
        "            sections.append(f\"‚Ä¢ {resp}\")\n",
        "        sections.append(\"\")\n",
        "    \n",
        "    # Requirements\n",
        "    if job['sections'].get('requirements'):\n",
        "        sections.append(\"Requirements:\")\n",
        "        for req in job['sections']['requirements']:\n",
        "            sections.append(f\"‚Ä¢ {req}\")\n",
        "        sections.append(\"\")\n",
        "    \n",
        "    # Nice to haves\n",
        "    if job['sections'].get('nice_to_haves'):\n",
        "        sections.append(\"Nice to Have:\")\n",
        "        for nice in job['sections']['nice_to_haves']:\n",
        "            sections.append(f\"‚Ä¢ {nice}\")\n",
        "        sections.append(\"\")\n",
        "    \n",
        "    return \"\\n\".join(sections)\n",
        "\n",
        "\"\"\"\n",
        "============================================================================================\n",
        "Create job embeddings\n",
        "============================================================================================\n",
        "\"\"\"\n",
        "def create_job_embeddings(input_file: str = \"data/job_descriptions_conglomerate.json\"):\n",
        "    \"\"\"Create vector embeddings for job descriptions.\"\"\"\n",
        "    \n",
        "    print(\"üöÄ Creating job description embeddings...\\n\")\n",
        "    \n",
        "    # Load job descriptions\n",
        "    print(f\"üìñ Loading job descriptions from {input_file}\")\n",
        "    with open(input_file, 'r', encoding='utf-8') as f:\n",
        "        jobs_data = json.load(f)\n",
        "    \n",
        "    print(f\"‚úÖ Loaded {len(jobs_data)} job descriptions\")\n",
        "    \n",
        "    # Transform data for vector database\n",
        "    print(\"\\nüîÑ Transforming job data for vector database...\")\n",
        "    transformed_data = transform_jobs_for_vectordb(jobs_data)\n",
        "    \n",
        "    total_chunks = sum(len(doc['chunks']) for doc in transformed_data)\n",
        "    print(f\"‚úÖ Created 1 document with {total_chunks} total chunks\")\n",
        "    \n",
        "    # Create vector database\n",
        "    print(f\"\\nüóÑÔ∏è Creating vector database: job_descriptions\")\n",
        "    db = VectorDB(name=\"job_descriptions\")\n",
        "    db.load_data(transformed_data)\n",
        "    \n",
        "    print(f\"‚úÖ Vector database created and saved!\")\n",
        "    \n",
        "    # Test search functionality\n",
        "    print(f\"\\nüîç Testing search functionality...\")\n",
        "    test_queries = [\n",
        "        \"software engineer python\",\n",
        "        \"marketing manager\", \n",
        "        \"product design\",\n",
        "        \"business development sales\"\n",
        "    ]\n",
        "\n",
        "    for query in test_queries:\n",
        "        results = db.search(query, k=3)\n",
        "        print(f\"\\nQuery: '{query}'\")\n",
        "        for i, result in enumerate(results[:2], 1):\n",
        "            metadata = result['metadata']\n",
        "            similarity = result['similarity']\n",
        "            job_title = metadata.get('job_title', 'Unknown')\n",
        "            department = metadata.get('department', 'Unknown')\n",
        "            print(f\"  {i}. {job_title} ({department}) (similarity: {similarity:.3f})\")\n",
        "    \n",
        "    return db"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating new pkl file & db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üéØ Job Descriptions Embedding Creator\n",
            "==================================================\n",
            "\n",
            "1Ô∏è‚É£ Creating vector embeddings...\n",
            "üöÄ Creating job description embeddings...\n",
            "\n",
            "üìñ Loading job descriptions from data/job_descriptions_conglomerate.json\n",
            "‚úÖ Loaded 236 job descriptions\n",
            "\n",
            "üîÑ Transforming job data for vector database...\n",
            "‚úÖ Created 1 document with 236 total chunks\n",
            "\n",
            "üóÑÔ∏è Creating vector database: job_descriptions\n",
            "Loading vector database from disk.\n",
            "‚úÖ Vector database created and saved!\n",
            "\n",
            "üîç Testing search functionality...\n",
            "\n",
            "Query: 'software engineer python'\n",
            "  1. Software Engineer (Engineering) (similarity: 0.420)\n",
            "  2. Data Engineer (Engineering) (similarity: 0.392)\n",
            "\n",
            "Query: 'marketing manager'\n",
            "  1. Head of Marketing (Business Operations & Strategy) (similarity: 0.437)\n",
            "  2. Product Manager (Product Management) (similarity: 0.419)\n",
            "\n",
            "Query: 'product design'\n",
            "  1. Product Designer (Product Management) (similarity: 0.394)\n",
            "  2. Product Designer (Product Management) (similarity: 0.394)\n",
            "\n",
            "Query: 'business development sales'\n",
            "  1. Business Development (Business Development) (similarity: 0.436)\n",
            "  2. Business Development Lead (Business Operations & Strategy) (similarity: 0.413)\n",
            "\n",
            "‚ú® Job embedding creation complete!\n"
          ]
        }
      ],
      "source": [
        "print(\"üéØ Job Descriptions Embedding Creator\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(\"\\n1Ô∏è‚É£ Creating vector embeddings...\")\n",
        "db = create_job_embeddings()\n",
        "\n",
        "print(\"\\n‚ú® Job embedding creation complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Actually generate JDs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìñ Loading vector database: job_descriptions\n",
            "‚úÖ Loaded 236 job descriptions\n",
            "\n",
            "============================================================\n",
            "üìÑ Senior Python Developer - Engineering\n",
            "============================================================\n",
            "\n",
            "**Job Description:**\n",
            "We're looking for an enthusiastic, self-motivated professional to join our team.\n",
            "\n",
            "**Key Responsibilities:**\n",
            "‚Ä¢ Design and develop robust APIs using Python and FastAPI to support scalable applications\n",
            "‚Ä¢ Lead discussions with product and design to rapidly iterate, experiment and launch products\n",
            "‚Ä¢ Design and build systems with an eye for performance & scalability\n",
            "‚Ä¢ Own products end to end and work across the stack as needed, including backend, database design, API development, testing, etc.\n",
            "‚Ä¢ Mentor team members on engineering best practices and career development\n",
            "\n",
            "**Requirements:**\n",
            "‚Ä¢ 5+ years of Python development experience\n",
            "‚Ä¢ Strong experience in API development and design\n",
            "‚Ä¢ Experience with database design and optimization\n",
            "‚Ä¢ Experience building and maintaining a production system at scale\n",
            "‚Ä¢ Experience with FastAPI, PostgreSQL or similar technologies\n",
            "‚Ä¢ Deep understanding of the architecture of modern applications\n",
            "‚Ä¢ Experience leading and aligning cross-functional stakeholders such as designers, engineers, and product managers to launch products\n",
            "‚Ä¢ Desire to keep up with modern best practices in software development/Web3, and shape our tech stack as we build out new systems and services\n",
            "\n",
            "**Nice to Have:**\n",
            "‚Ä¢ Experience with cloud providers such as AWS, GCP\n",
            "‚Ä¢ Love for unicorns :)\n"
          ]
        }
      ],
      "source": [
        "# Import and use directly\n",
        "from misc.job_description_generator import JobGenerator, generate_job_description\n",
        "\n",
        "# One-liner generation\n",
        "job_desc = generate_job_description(\n",
        "    job_title=\"Senior Python Developer\",\n",
        "    department=\"Engineering\", \n",
        "    requirements=[\"5+ years Python\", \"API development\", \"Database design\"],\n",
        "    seniority=\"senior\",\n",
        "    skills=[\"Python\", \"FastAPI\", \"PostgreSQL\"]\n",
        ")\n",
        "\n",
        "# Or use the class for more control\n",
        "generator = JobGenerator(verbose=False)  # Silent mode\n",
        "job_desc = generator.generate(\n",
        "    job_title=\"Marketing Manager\",\n",
        "    department=\"Marketing\",\n",
        "    key_requirements=[\"3+ years marketing\", \"Campaign management\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìñ Loading Employee Handbook data for contextual RAG...\n",
            "üîÑ Creating contextual embeddings for Employee Handbook...\n",
            "Processing 77 Employee Handbook chunks...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding contextual information to Employee Handbook: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 77/77 [09:12<00:00,  7.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Contextual information added for Employee Handbook!\n",
            "üìÑ Enhanced chunks saved to ../data/employee_handbook_with_context.json\n",
            "‚úÖ Created contextual embeddings with 77 chunks\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from data_utils import setup_contextual_embeddings\n",
        "\n",
        "# This will automatically create the contextual embeddings if they don't exist\n",
        "raw_chunks, enhanced_chunks = setup_contextual_embeddings('employee_handbook')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
