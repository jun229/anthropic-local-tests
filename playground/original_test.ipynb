{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3a14458",
   "metadata": {},
   "source": [
    "# Enhancing RAG with Contextual Retrieval\n",
    "\n",
    "> Note: For more background information on Contextual Retrieval, including additional performance evaluations on various datasets, we recommend reading our accompanying  [blog post](https://www.anthropic.com/news/contextual-retrieval).\n",
    "\n",
    "Retrieval Augmented Generation (RAG) enables Claude to leverage your internal knowledge bases, codebases, or any other corpus of documents when providing a response. Enterprises are increasingly building RAG applications to improve workflows in customer support, Q&A over internal company documents, financial & legal analysis, code generation, and much more.\n",
    "\n",
    "In a [separate guide](https://github.com/anthropics/anthropic-cookbook/blob/main/skills/retrieval_augmented_generation/guide.ipynb), we walked through setting up a basic retrieval system, demonstrated how to evaluate its performance, and then outlined a few techniques to improve performance. In this guide, we present a technique for improving retrieval performance: Contextual Embeddings.\n",
    "\n",
    "In traditional RAG, documents are typically split into smaller chunks for efficient retrieval. While this approach works well for many applications, it can lead to problems when individual chunks lack sufficient context. Contextual Embeddings solve this problem by adding relevant context to each chunk before embedding. This method improves the quality of each embedded chunk, allowing for more accurate retrieval and thus better overall performance. Averaged across all data sources we tested, Contextual Embeddings reduced the top-20-chunk retrieval failure rate by 35%.\n",
    "\n",
    "The same chunk-specific context can also be used with BM25 search to further improve retrieval performance. We introduce this technique in the “Contextual BM25” section.\n",
    "\n",
    "In this guide, we'll demonstrate how to build and optimize a Contextual Retrieval system using a dataset of 9 codebases as our knowledge base. We'll walk through:\n",
    "\n",
    "1) Setting up a basic retrieval pipeline to establish a baseline for performance.\n",
    "\n",
    "2) Contextual Embeddings: what it is, why it works, and how prompt caching makes it practical for production use cases.\n",
    "\n",
    "3) Implementing Contextual Embeddings and demonstrating performance improvements.\n",
    "\n",
    "4) Contextual BM25: improving performance with *contextual* BM25 hybrid search.\n",
    "\n",
    "5) Improving performance with reranking,\n",
    "\n",
    "### Evaluation Metrics & Dataset:\n",
    "\n",
    "We use a pre-chunked dataset of 9 codebases - all of which have been chunked according to a basic character splitting mechanism. Our evaluation dataset contains 248 queries - each of which contains a 'golden chunk.' We'll use a metric called Pass@k to evaluate performance. Pass@k checks whether or not the 'golden document' was present in the first k documents retrieved for each query. Contextual Embeddings in this case helped us to improve Pass@10 performance from ~87% --> ~95%.\n",
    "\n",
    "You can find the code files and their chunks in `data/codebase_chunks.json` and the evaluation dataset in `data/evaluation_set.jsonl`\n",
    "\n",
    "#### Additional Notes:\n",
    "\n",
    "Prompt caching is helpful in managing costs when using this retrieval method. This feature is currently available on Anthropic's 1P API, and is coming soon to our 3P partner environments in AWS Bedrock and GCP Vertex. We know that many of our customers leverage AWS Knowledge Bases and GCP Vertex AI APIs when building RAG solutions, and this method can be used on either platform with a bit of customization. Consider reaching out to Anthropic or your AWS/GCP account team for guidance on this!\n",
    "\n",
    "To make it easier to use this method on Bedrock, the AWS team has provided us with code that you can use to implement a Lambda function that adds context to each document. If you deploy this Lambda function, you can select it as a custom chunking option when configuring a [Bedrock Knowledge Base](https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base-create.html). You can find this code in `contextual-rag-lambda-function`. The main lambda function code is in `lambda_function.py`.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1) Setup\n",
    "\n",
    "2) Basic RAG\n",
    "\n",
    "3) Contextual Embeddings\n",
    "\n",
    "4) Contextual BM25\n",
    "\n",
    "5) Reranking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfbd3f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: anthropic in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (0.58.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from anthropic) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from anthropic) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from anthropic) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from anthropic) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from anthropic) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from anthropic) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from anthropic) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from httpx<1,>=0.25.0->anthropic) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->anthropic) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: openai in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (1.97.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: cohere in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (5.16.1)\n",
      "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from cohere) (1.11.1)\n",
      "Requirement already satisfied: httpx>=0.21.2 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from cohere) (0.28.1)\n",
      "Requirement already satisfied: httpx-sse==0.4.0 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from cohere) (0.4.0)\n",
      "Requirement already satisfied: pydantic>=1.9.2 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from cohere) (2.11.7)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from cohere) (2.33.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from cohere) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from cohere) (0.21.2)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from cohere) (2.32.4.20250611)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from cohere) (4.14.1)\n",
      "Requirement already satisfied: anyio in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from httpx>=0.21.2->cohere) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from httpx>=0.21.2->cohere) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from httpx>=0.21.2->cohere) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from httpx>=0.21.2->cohere) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from pydantic>=1.9.2->cohere) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.0.0->cohere) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.0.0->cohere) (2.5.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from tokenizers<1,>=0.15->cohere) (0.33.4)\n",
      "Requirement already satisfied: filelock in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2025.7.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (1.1.5)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from anyio->httpx>=0.21.2->cohere) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: elasticsearch in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (9.0.2)\n",
      "Requirement already satisfied: elastic-transport<9,>=8.15.1 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from elasticsearch) (8.17.1)\n",
      "Requirement already satisfied: python-dateutil in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from elasticsearch) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-extensions in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from elasticsearch) (4.14.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (2.5.0)\n",
      "Requirement already satisfied: certifi in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (2025.7.14)\n",
      "Requirement already satisfied: six>=1.5 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from python-dateutil->elasticsearch) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pandas in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from pandas) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: numpy in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (2.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from matplotlib) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: tqdm in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (4.67.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: python-dotenv in /Users/brian.liu/Desktop/Coding/anthropic-local-test/.venv/lib/python3.13/site-packages (1.1.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install anthropic\n",
    "!pip install openai\n",
    "!pip install cohere\n",
    "!pip install elasticsearch\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install tqdm\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4352c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get API keys from environment variables\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY') \n",
    "ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')\n",
    "COHERE_API_KEY = os.getenv('COHERE_API_KEY') # Im running on a free student version of cohere ,-,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "741ba258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "\n",
    "client = anthropic.Anthropic(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.getenv(\"ANTHROPIC_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715f9402",
   "metadata": {},
   "source": [
    "## Level 1: Naive RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c9763a",
   "metadata": {},
   "source": [
    "### Initialize a Vector DB Class\n",
    "\n",
    "In-memory vector DB, for example purposes.\n",
    "Can host it for more production related tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a6820b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from typing import List, Dict, Any\n",
    "from tqdm import tqdm\n",
    "\n",
    "class VectorDB:\n",
    "    def __init__(self, name: str, api_key = None):\n",
    "        if api_key is None:\n",
    "            api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        self.name = name\n",
    "        self.embeddings = []\n",
    "        self.metadata = []\n",
    "        self.query_cache = {}\n",
    "        self.db_path = f\"./data/{name}/vector_db.pkl\"\n",
    "\n",
    "    def load_data(self, dataset: List[Dict[str, Any]]):\n",
    "        if self.embeddings and self.metadata:\n",
    "            print(\"Vector database is already loaded. Skipping data loading.\")\n",
    "            return\n",
    "        if os.path.exists(self.db_path):\n",
    "            print(\"Loading vector database from disk.\")\n",
    "            self.load_db()\n",
    "            return\n",
    "\n",
    "        texts_to_embed = []\n",
    "        metadata = []\n",
    "        total_chunks = sum(len(doc['chunks']) for doc in dataset)\n",
    "        \n",
    "        with tqdm(total=total_chunks, desc=\"Processing chunks\") as pbar:\n",
    "            for doc in dataset:\n",
    "                for chunk in doc['chunks']:\n",
    "                    texts_to_embed.append(chunk['content'])\n",
    "                    metadata.append({\n",
    "                        'doc_id': doc['doc_id'],\n",
    "                        'original_uuid': doc['original_uuid'],\n",
    "                        'chunk_id': chunk['chunk_id'],\n",
    "                        'original_index': chunk['original_index'],\n",
    "                        'content': chunk['content']\n",
    "                    })\n",
    "                    pbar.update(1)\n",
    "\n",
    "        self._embed_and_store(texts_to_embed, metadata)\n",
    "        self.save_db()\n",
    "        \n",
    "        print(f\"Vector database loaded and saved. Total chunks processed: {len(texts_to_embed)}\")\n",
    "    \n",
    "    # for chatgpt\n",
    "    def _chunk_text(self, text, max_tokens=7000, overlap_tokens=500):\n",
    "        \"\"\"Split text into overlapping chunks that fit within token limits\"\"\"\n",
    "        # Rough estimate: 1 token ≈ 4 characters\n",
    "        max_chars = max_tokens * 4\n",
    "        overlap_chars = overlap_tokens * 4\n",
    "        \n",
    "        if len(text) <= max_chars:\n",
    "            return [text]\n",
    "        \n",
    "        chunks = []\n",
    "        start = 0\n",
    "        \n",
    "        while start < len(text):\n",
    "            end = start + max_chars\n",
    "            \n",
    "            # If this isn't the last chunk, try to break at a sentence or paragraph\n",
    "            if end < len(text):\n",
    "                # Look for sentence endings in the last 500 characters\n",
    "                break_point = text.rfind('.', end - 500, end)\n",
    "                if break_point == -1:\n",
    "                    break_point = text.rfind('\\n', end - 500, end)\n",
    "                if break_point != -1:\n",
    "                    end = break_point + 1\n",
    "            \n",
    "            chunk = text[start:end]\n",
    "            chunks.append(chunk)\n",
    "            \n",
    "            # Move start position, accounting for overlap\n",
    "            if end >= len(text):\n",
    "                break\n",
    "            start = end - overlap_chars\n",
    "            \n",
    "        print(f\"Split text of {len(text)} characters into {len(chunks)} chunks\")\n",
    "        return chunks\n",
    "\n",
    "\n",
    "    def _embed_and_store(self, texts: List[str], data: List[Dict[str, Any]]):\n",
    "        batch_size = 100\n",
    "        with tqdm(total=len(texts), desc=\"Embedding chunks\") as pbar:\n",
    "            result = []\n",
    "            for i in range(0, len(texts), batch_size):\n",
    "                batch = texts[i : i + batch_size]\n",
    "                response = self.client.embeddings.create(\n",
    "                    input = batch,\n",
    "                    model='text-embedding-3-small'\n",
    "                )\n",
    "                \n",
    "                batch_embeddings = [item.embedding for item in response.data]\n",
    "                result.extend(batch_embeddings)\n",
    "                pbar.update(len(batch))\n",
    "        \n",
    "        self.embeddings = result\n",
    "        self.metadata = data\n",
    "\n",
    "    def search(self, query: str, k: int = 20) -> List[Dict[str, Any]]:\n",
    "        if query in self.query_cache:\n",
    "            query_embedding = self.query_cache[query]\n",
    "        else:\n",
    "            query_embedding = self.client.embeddings.create(\n",
    "                input = [query], \n",
    "                model=\"text-embedding-3-small\"\n",
    "                ).data[0].embedding\n",
    "            self.query_cache[query] = query_embedding\n",
    "\n",
    "        if not self.embeddings:\n",
    "            raise ValueError(\"No data loaded in the vector database.\")\n",
    "\n",
    "        similarities = np.dot(self.embeddings, query_embedding)\n",
    "        top_indices = np.argsort(similarities)[::-1][:k]\n",
    "        \n",
    "        top_results = []\n",
    "\n",
    "        for idx in top_indices:\n",
    "            result = {\n",
    "                \"metadata\": self.metadata[idx],\n",
    "                \"similarity\": float(similarities[idx]),\n",
    "            }\n",
    "            top_results.append(result)\n",
    "        \n",
    "        return top_results\n",
    "\n",
    "    def save_db(self):\n",
    "        data = {\n",
    "            \"embeddings\": self.embeddings,\n",
    "            \"metadata\": self.metadata,\n",
    "            \"query_cache\": json.dumps(self.query_cache),\n",
    "        }\n",
    "        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)\n",
    "        with open(self.db_path, \"wb\") as file:\n",
    "            pickle.dump(data, file)\n",
    "\n",
    "    def load_db(self):\n",
    "        if not os.path.exists(self.db_path):\n",
    "            raise ValueError(\"Vector database file not found. Use load_data to create a new database.\")\n",
    "        with open(self.db_path, \"rb\") as file:\n",
    "            data = pickle.load(file)\n",
    "        self.embeddings = data[\"embeddings\"]\n",
    "        self.metadata = data[\"metadata\"]\n",
    "        self.query_cache = json.loads(data[\"query_cache\"])\n",
    "\n",
    "    def validate_embedded_chunks(self):\n",
    "        unique_contents = set()\n",
    "        for meta in self.metadata:\n",
    "            unique_contents.add(meta['content'])\n",
    "    \n",
    "        print(f\"Validation results:\")\n",
    "        print(f\"Total embedded chunks: {len(self.metadata)}\")\n",
    "        print(f\"Unique embedded contents: {len(unique_contents)}\")\n",
    "    \n",
    "        if len(self.metadata) != len(unique_contents):\n",
    "            print(\"Warning: There may be duplicate chunks in the embedded data.\")\n",
    "        else:\n",
    "            print(\"All embedded chunks are unique.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513ecf73",
   "metadata": {},
   "source": [
    "## Level 1 - Basic RAG\n",
    "\n",
    "To get started, we'll set up a basic RAG pipeline using a bare bones approach. This is sometimes called 'Naive RAG' by many in the industry. A basic RAG pipeline includes the following 3 steps:\n",
    "\n",
    "1) Chunk documents by heading - containing only the content from each subheading\n",
    "\n",
    "2) Embed each document\n",
    "\n",
    "3) Use Cosine similarity to retrieve documents in order to answer query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc27a09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks: 100%|██████████| 77/77 [00:00<00:00, 819699.01it/s]\n",
      "Embedding chunks: 100%|██████████| 77/77 [00:01<00:00, 56.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector database loaded and saved. Total chunks processed: 77\n",
      "Loaded 77 chunks into VectorDB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load and transform the benefits_wellbeing data\n",
    "# Create the corresponding Pickle file for the VectorDB\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from typing import Callable, List, Dict, Any, Tuple, Set\n",
    "\n",
    "with open('data/employee_handbook.json', 'r') as f:\n",
    "    employee_handbook_raw = json.load(f)\n",
    "\n",
    "def transform_data_for_vectordb(raw_data):\n",
    "    \"\"\"Transform the benefits_wellbeing data to match VectorDB structure\"\"\"\n",
    "    transformed = []\n",
    "    \n",
    "    # Create a single document containing all chunks\n",
    "    doc = {\n",
    "        \"doc_id\": \"benefits_wellbeing\",\n",
    "        \"original_uuid\": \"benefits_wellbeing_doc\",\n",
    "        \"chunks\": []\n",
    "    }\n",
    "    \n",
    "    for i, item in enumerate(raw_data):\n",
    "        chunk = {\n",
    "            \"chunk_id\": f\"chunk_{i}\",\n",
    "            \"original_index\": i,\n",
    "            \"content\": item[\"text\"],\n",
    "            \"heading\": item[\"chunk_heading\"],\n",
    "            \"link\": item[\"chunk_link\"]\n",
    "        }\n",
    "        doc[\"chunks\"].append(chunk)\n",
    "    \n",
    "    transformed.append(doc)\n",
    "    return transformed\n",
    "\n",
    "# Transform the data to match VectorDB expected structure\n",
    "employee_handbook = transform_data_for_vectordb(employee_handbook_raw)\n",
    "\n",
    "# Initialize the VectorDB\n",
    "db = VectorDB(\"employee_handbook\")\n",
    "db.load_data(employee_handbook)\n",
    "\n",
    "print(f\"Loaded {len(employee_handbook[0]['chunks'])} chunks into VectorDB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a94a662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG Functions\n",
    "\n",
    "def retrieve_base(query, db, k=5):\n",
    "    \"\"\"Retrieve relevant documents and format context\"\"\"\n",
    "    results = db.search(query, k=k)\n",
    "    context = \"\"\n",
    "    for result in results:\n",
    "        chunk = result['metadata']\n",
    "        context += f\"\\n{chunk['content']}\\n\"\n",
    "    return results, context\n",
    "\n",
    "def answer_query_base(query, db):\n",
    "    \"\"\"Answer a query using the RAG pipeline\"\"\"\n",
    "    documents, context = retrieve_base(query, db)\n",
    "    prompt = f\"\"\" ### SYSTEM ###\n",
    "    You are **Uniswap Benefits Assistant**.\n",
    "\n",
    "    You have been provided with relevant company documents to answer employee questions.\n",
    "\n",
    "    **Workflow for this query:**\n",
    "    1. **Analyze the user question**: {query}\n",
    "    2. **Review the provided context** below for relevant information\n",
    "    3. **Write a natural-language answer** following these rules:\n",
    "    • Use only facts that appear verbatim in the provided context\n",
    "    • If the information isn't in the context, reply: \"I don't have that information in the provided context.\"\n",
    "    • Compose the most **expansive, detailed answer possible** by weaving together **every relevant fact** found in the context—rephrasing, grouping, and elaborating on those facts for clarity and flow\n",
    "    • You may explain terms, list related details, and provide a logical structure\n",
    "    • **Never introduce information that is not stated verbatim in the context**\n",
    "    • **Always aim to reduce verbosity**\n",
    "    4. **Do not** provide preamble such as \"Here is the answer\" or \"Based on the documents\"\n",
    "    5. **Always append exactly**: \"Double-check with Julian or Megan for any of this information!\"\n",
    "\n",
    "    ### USER QUESTION ###\n",
    "    {query}\n",
    "\n",
    "    ### CONTEXT ###\n",
    "    {context}\n",
    "\n",
    "    ### RESPONSE ###\"\"\"\n",
    "    \n",
    "    response = client.messages.create(\n",
    "        model=\"claude-sonnet-4-20250514\", #output should use a stronger model than context enrichment models\n",
    "        max_tokens=2500,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0 #creates a deterministic, more factual response\n",
    "    )\n",
    "    # Handle the response content properly\n",
    "    try:\n",
    "        return response.content[0].text\n",
    "    except AttributeError:\n",
    "        return str(response.content[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9985a3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Do we get any sort of wfh-setup-refresh benefits? I'm tormented by the fact that I didn't get a proper chair within my first year of joining\n",
      "Answer: Uniswap Labs provides a Home Office Set up benefit for remote employees, which reimburses up to $2,000 USD to cover the purchase of office supplies, productivity items, and anything else you might need to get your home office set up. This benefit is designed to help you create a proper workspace at home.\n",
      "\n",
      "However, I don't have information in the provided context about whether this is a one-time benefit or if there are periodic refresh opportunities for work-from-home setup expenses beyond the initial $2,000 reimbursement.\n",
      "\n",
      "Additionally, if you prefer working from a co-working space instead of your home office, Uniswap Labs reimburses the cost up to $500 USD per month for co-working space expenses.\n",
      "\n",
      "Double-check with Julian or Megan for any of this information!\n"
     ]
    }
   ],
   "source": [
    "# Test the naive RAG system\n",
    "test_query = \"Do we get any sort of wfh-setup-refresh benefits? I'm tormented by the fact that I didn't get a proper chair within my first year of joining\"\n",
    "answer = answer_query_base(test_query, db)\n",
    "print(f\"Query: {test_query}\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56630c3f",
   "metadata": {},
   "source": [
    "## Level 2: Contextual Embeddings\n",
    "\n",
    "With basic RAG, each embedded chunk contains a potentially useful piece of information, but these chunks lack context. With Contextual Embeddings, we create a variation on the embedding itself by adding more context to each text chunk before embedding it. Specifically, we use Claude to create a concise context that explains the chunk using the context of the overall document. In the case of our codebases dataset, we can provide both the chunk and the full file that each chunk was found within to an LLM, then produce the context. Then, we will combine this 'context' and the raw text chunk together into a single text block prior to creating each embedding.\n",
    "\n",
    "### Additional Considerations: Cost and Latency\n",
    "\n",
    "The extra work we're doing to 'situate' each document happens only at ingestion time: it's a cost you'll pay once when you store each document (and periodically in the future if you have a knowledge base that updates over time). There are many approaches like HyDE (hypothetical document embeddings) which involve performing steps to improve the representation of the query prior to executing a search. These techniques have shown to be moderately effective, but they add significant latency at runtime.\n",
    "\n",
    "[Prompt caching](https://docs.anthropic.com/en/docs/build-with-claude/prompt-caching) also makes this much more cost effective. Creating contextual embeddings requires us to pass the same document to the model for every chunk we want to generate extra context for. With prompt caching, we can write the overall doc to the cache once, and then because we're doing our ingestion job all in sequence, we can just read the document from cache as we generate context for each chunk within that document (the information you write to the cache has a 5 minute time to live). This means that the first time we pass a document to the model, we pay a bit more to write it to the cache, but for each subsequent API call that contains that doc, we receive  a 90% discount on all of the input tokens read from the cache. Assuming 800 token chunks, 8k token documents, 50 token context instructions, and 100 tokens of context per chunk, the cost to generate contextualized chunks is $1.02 per million document tokens.\n",
    "\n",
    "When you load data into your ContextualVectorDB below, you'll see in logs just how big this impact is. \n",
    "\n",
    "Warning: some smaller embedding models have a fixed input token limit. Contextualizing the chunk makes it longer, so if you notice much worse performance from contextualized embeddings, the contextualized chunk is likely getting truncated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d330188",
   "metadata": {},
   "source": [
    "#### Create the contextual chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00852d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 5 benefits chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding contextual information: 100%|██████████| 5/5 [00:07<00:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contextual information added! Enhanced chunks saved to data/benefits_wellbeing_with_context.json\n",
      "\n",
      "Preview of contextual information for first 2 chunks:\n",
      "============================================================\n",
      "\n",
      "Chunk 1: Health Benefits\n",
      "Original text length: 2176 characters\n",
      "Situational Context: The Health Benefits section outlines the various health insurance plans, including medical, dental, and vision, that Uniswap offers to its employees as part of their comprehensive benefits package. This section provides details on the specific providers, plan options, and resources available to help employees navigate and access these health-related benefits.\n",
      "----------------------------------------\n",
      "\n",
      "Chunk 2: Leaves\n",
      "Original text length: 15766 characters\n",
      "Situational Context: This section on Leaves, including Parental Leave and Unpaid Leaves of Absence, is part of Uniswap's comprehensive Benefits & Wellbeing documentation for employees. It outlines the company's policies and processes around various types of leaves, providing details on eligibility, procedures, and FAQs to help employees navigate these benefits.\n",
      "----------------------------------------\n",
      "\n",
      "✅ Complete! Your enhanced chunks are ready for RAG at: data/benefits_wellbeing_with_context.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from anthropic import Anthropic\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize Anthropic client\n",
    "client = Anthropic()\n",
    "\n",
    "# Template for the full benefits document\n",
    "BENEFITS_DOCUMENT_CONTEXT_PROMPT = \"\"\"\n",
    "<document>\n",
    "This is Uniswap Labs' comprehensive Benefits & Wellbeing documentation for employees. \n",
    "It covers health insurance, leave policies, perks, financial benefits, and time-off policies.\n",
    "\n",
    "{doc_content}\n",
    "</document>\n",
    "\"\"\"\n",
    "\n",
    "# Template for contextualizing individual chunks\n",
    "CHUNK_CONTEXT_PROMPT = \"\"\"\n",
    "Here is a specific section from Uniswap's benefits documentation that we want to situate within the overall benefits package:\n",
    "\n",
    "<chunk>\n",
    "Section: {chunk_heading}\n",
    "{chunk_content}\n",
    "</chunk>\n",
    "\n",
    "Please provide a short, succinct context to situate this benefits section within Uniswap's overall employee benefits package. This context will help employees find this information when searching for related benefits topics.\n",
    "\n",
    "Answer only with the succinct context and nothing else.\n",
    "\"\"\"\n",
    "\n",
    "def situate_benefits_context(full_benefits_doc: str, chunk_heading: str, chunk_content: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate contextual information for a benefits chunk within the full benefits document\n",
    "    \"\"\"\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-haiku-20240307\",\n",
    "        max_tokens=150,  # Keep context concise\n",
    "        temperature=0.0,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": BENEFITS_DOCUMENT_CONTEXT_PROMPT.format(doc_content=full_benefits_doc),\n",
    "                        \"cache_control\": {\"type\": \"ephemeral\"}  # Cache the full benefits doc\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": CHUNK_CONTEXT_PROMPT.format(\n",
    "                            chunk_heading=chunk_heading,\n",
    "                            chunk_content=chunk_content\n",
    "                        ),\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        extra_headers={\"anthropic-beta\": \"prompt-caching-2024-07-31\"}\n",
    "    )\n",
    "    return response.content[0].text.strip()\n",
    "\n",
    "def add_contextual_information(input_file, output_file, original_markdown_file):\n",
    "    \"\"\"\n",
    "    Process all benefits chunks to add contextual information\n",
    "    \"\"\"\n",
    "    # Load the chunked JSON data\n",
    "    with open(input_file, 'r') as f:\n",
    "        chunks = json.load(f)\n",
    "    \n",
    "    # Load the original full markdown document for context\n",
    "    with open(original_markdown_file, 'r') as f:\n",
    "        full_benefits_doc = f.read()\n",
    "    \n",
    "    print(f\"Processing {len(chunks)} benefits chunks...\")\n",
    "    \n",
    "    enhanced_chunks = []\n",
    "    \n",
    "    for chunk in tqdm(chunks, desc=\"Adding contextual information\"):\n",
    "        try:\n",
    "            # Generate situational context\n",
    "            situational_context = situate_benefits_context(\n",
    "                full_benefits_doc=full_benefits_doc,\n",
    "                chunk_heading=chunk['chunk_heading'],\n",
    "                chunk_content=chunk['text']\n",
    "            )\n",
    "            \n",
    "            # Create enhanced chunk\n",
    "            enhanced_chunk = {\n",
    "                \"chunk_link\": chunk[\"chunk_link\"],\n",
    "                \"chunk_heading\": chunk[\"chunk_heading\"],\n",
    "                \"text\": chunk[\"text\"],\n",
    "                \"situational_context\": situational_context\n",
    "            }\n",
    "            \n",
    "            enhanced_chunks.append(enhanced_chunk)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing chunk '{chunk['chunk_heading']}': {e}\")\n",
    "            # Add chunk without context if there's an error\n",
    "            enhanced_chunks.append(chunk)\n",
    "    \n",
    "    # Save the enhanced chunks\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(enhanced_chunks, f, indent=2)\n",
    "    \n",
    "    print(f\"Contextual information added! Enhanced chunks saved to {output_file}\")\n",
    "    return enhanced_chunks\n",
    "\n",
    "def preview_contextual_chunks(chunks, num_chunks=2):\n",
    "    \"\"\"Preview the contextual information added to chunks\"\"\"\n",
    "    print(f\"\\nPreview of contextual information for first {num_chunks} chunks:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i, chunk in enumerate(chunks[:num_chunks]):\n",
    "        print(f\"\\nChunk {i+1}: {chunk['chunk_heading']}\")\n",
    "        print(f\"Original text length: {len(chunk['text'])} characters\")\n",
    "        if 'situational_context' in chunk:\n",
    "            print(f\"Situational Context: {chunk['situational_context']}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # File paths - update these to match your setup\n",
    "    input_json = \"data/benefits_wellbeing.json\"  # Your chunked JSON from the markdown converter\n",
    "    original_markdown = \"data/Benefits & Wellbeing.md\"  # Your original markdown file\n",
    "    output_json = \"data/benefits_wellbeing_with_context.json\"  # Output with contextual info\n",
    "    \n",
    "    try:\n",
    "        # Process the chunks to add contextual information\n",
    "        enhanced_chunks = add_contextual_information(\n",
    "            input_file=input_json,\n",
    "            output_file=output_json,\n",
    "            original_markdown_file=original_markdown\n",
    "        )\n",
    "        \n",
    "        # Preview the results\n",
    "        preview_contextual_chunks(enhanced_chunks)\n",
    "        \n",
    "        print(f\"\\n✅ Complete! Your enhanced chunks are ready for RAG at: {output_json}\")\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"❌ Error: Could not find file - {e}\")\n",
    "        print(\"Please make sure your file paths are correct.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during processing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085311bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 chunks from benefits_wellbeing.json\n",
      "Full document length: 41272 characters\n",
      "✅ Created contextual dataset with 5 chunks\n",
      "✅ Saved to: data/benefits_wellbeing_contextual_format.json\n"
     ]
    }
   ],
   "source": [
    "def create_contextual_dataset():\n",
    "    \"\"\"\n",
    "    Transform benefits_wellbeing_with_context data to match ContextualVectorDB expected format\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the original chunked data\n",
    "    with open('data/benefits_wellbeing_with_context.json', 'r') as f:\n",
    "        chunks_data = json.load(f)\n",
    "    \n",
    "    # Load the full markdown document content\n",
    "    with open('data/Benefits & Wellbeing.md', 'r') as f:\n",
    "        full_document_content = f.read()\n",
    "    \n",
    "    print(f\"Loaded {len(chunks_data)} chunks from benefits_wellbeing.json\")\n",
    "    print(f\"Full document length: {len(full_document_content)} characters\")\n",
    "    \n",
    "    # Create the properly formatted dataset\n",
    "    contextual_dataset = [{\n",
    "        \"doc_id\": \"benefits_wellbeing\",\n",
    "        \"original_uuid\": \"benefits_wellbeing_uuid\", \n",
    "        \"content\": full_document_content,  # This is what ContextualVectorDB needs!\n",
    "        \"chunks\": []\n",
    "    }]\n",
    "    \n",
    "    # Transform each chunk to the expected format\n",
    "    for i, chunk in enumerate(chunks_data):\n",
    "        formatted_chunk = {\n",
    "            \"chunk_id\": f\"chunk_{i}\",\n",
    "            \"original_index\": i,\n",
    "            \"content\": chunk[\"text\"],  # Change from 'text' to 'content'\n",
    "            \"heading\": chunk[\"chunk_heading\"],\n",
    "            \"link\": chunk[\"chunk_link\"]\n",
    "        }\n",
    "        contextual_dataset[0][\"chunks\"].append(formatted_chunk)\n",
    "    \n",
    "    # Save the transformed dataset\n",
    "    output_file = 'data/benefits_wellbeing_contextualDBformat.json'\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(contextual_dataset, f, indent=2)\n",
    "    \n",
    "    print(f\"✅ Created contextual dataset with {len(contextual_dataset[0]['chunks'])} chunks\")\n",
    "    print(f\"✅ Saved to: {output_file}\")\n",
    "    \n",
    "    return contextual_dataset\n",
    "\n",
    "# Create the properly formatted dataset\n",
    "contextual_dataset = create_contextual_dataset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e94cfe",
   "metadata": {},
   "source": [
    "#### New DB, ContextualDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa8f6dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ContextualVectorDB class ready!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from typing import List, Dict, Any\n",
    "from tqdm import tqdm\n",
    "import anthropic\n",
    "import threading\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "class ContextualVectorDB:\n",
    "    def __init__(self, name: str, anthropic_api_key=None, openai_api_key=None):\n",
    "        if anthropic_api_key is None:\n",
    "            anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "        if openai_api_key is None:\n",
    "            openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        \n",
    "        self.anthropic_client = anthropic.Anthropic(api_key=anthropic_api_key)\n",
    "        self.openai_client = OpenAI(api_key=openai_api_key)\n",
    "        self.name = name\n",
    "        self.embeddings = []\n",
    "        self.metadata = []\n",
    "        self.query_cache = {}\n",
    "        self.db_path = f\"./data/{name}/contextual_vector_db.pkl\"\n",
    "\n",
    "        self.token_counts = {\n",
    "            'input': 0,\n",
    "            'output': 0,\n",
    "            'cache_read': 0,\n",
    "            'cache_creation': 0\n",
    "        }\n",
    "        self.token_lock = threading.Lock()\n",
    "\n",
    "    def situate_context(self, doc: str, chunk: str) -> tuple[str, Any]:\n",
    "        DOCUMENT_CONTEXT_PROMPT = \"\"\"\n",
    "        <document>\n",
    "        {doc_content}\n",
    "        </document>\n",
    "        \"\"\"\n",
    "\n",
    "        CHUNK_CONTEXT_PROMPT = \"\"\"\n",
    "        Here is the chunk we want to situate within the whole document\n",
    "        <chunk>\n",
    "        {chunk_content}\n",
    "        </chunk>\n",
    "\n",
    "        Please give a short succinct context to situate this chunk within the overall document for the purposes of improving search retrieval of the chunk.\n",
    "        Answer only with the succinct context and nothing else.\n",
    "        \"\"\"\n",
    "\n",
    "        response = self.anthropic_client.messages.create(\n",
    "            model=\"claude-3-haiku-20240307\",\n",
    "            max_tokens=1000,\n",
    "            temperature=0.0,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": DOCUMENT_CONTEXT_PROMPT.format(doc_content=doc),\n",
    "                            \"cache_control\": {\"type\": \"ephemeral\"} #we will make use of prompt caching for the full documents\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": CHUNK_CONTEXT_PROMPT.format(chunk_content=chunk),\n",
    "                        },\n",
    "                    ]\n",
    "                },\n",
    "            ],\n",
    "            extra_headers={\"anthropic-beta\": \"prompt-caching-2024-07-31\"}\n",
    "        )\n",
    "        # Handle the response content properly\n",
    "        try:\n",
    "            response_text = response.content[0].text\n",
    "        except AttributeError:\n",
    "            response_text = str(response.content[0])\n",
    "        return response_text, response.usage\n",
    "\n",
    "    def load_data(self, dataset: List[Dict[str, Any]], parallel_threads: int = 1):\n",
    "        if self.embeddings and self.metadata:\n",
    "            print(\"Vector database is already loaded. Skipping data loading.\")\n",
    "            return\n",
    "        if os.path.exists(self.db_path):\n",
    "            print(\"Loading vector database from disk.\")\n",
    "            self.load_db()\n",
    "            return\n",
    "\n",
    "        texts_to_embed = []\n",
    "        metadata = []\n",
    "        total_chunks = sum(len(doc['chunks']) for doc in dataset)\n",
    "\n",
    "        def process_chunk(doc, chunk):\n",
    "            #for each chunk, produce the context\n",
    "            contextualized_text, usage = self.situate_context(doc['content'], chunk['content'])\n",
    "            with self.token_lock:\n",
    "                self.token_counts['input'] += usage.input_tokens\n",
    "                self.token_counts['output'] += usage.output_tokens\n",
    "                self.token_counts['cache_read'] += usage.cache_read_input_tokens\n",
    "                self.token_counts['cache_creation'] += usage.cache_creation_input_tokens\n",
    "            \n",
    "            return {\n",
    "                #append the context to the original text chunk\n",
    "                'text_to_embed': f\"{chunk['content']}\\\\n\\\\n{contextualized_text}\",\n",
    "                'metadata': {\n",
    "                    'doc_id': doc['doc_id'],\n",
    "                    'original_uuid': doc['original_uuid'],\n",
    "                    'chunk_id': chunk['chunk_id'],\n",
    "                    'original_index': chunk['original_index'],\n",
    "                    'original_content': chunk['content'],\n",
    "                    'contextualized_content': contextualized_text\n",
    "                }\n",
    "            }\n",
    "\n",
    "        print(f\"Processing {total_chunks} chunks with {parallel_threads} threads\")\n",
    "        with ThreadPoolExecutor(max_workers=parallel_threads) as executor:\n",
    "            futures = []\n",
    "            for doc in dataset:\n",
    "                for chunk in doc['chunks']:\n",
    "                    futures.append(executor.submit(process_chunk, doc, chunk))\n",
    "            \n",
    "            for future in tqdm(as_completed(futures), total=total_chunks, desc=\"Processing chunks\"):\n",
    "                result = future.result()\n",
    "                texts_to_embed.append(result['text_to_embed'])\n",
    "                metadata.append(result['metadata'])\n",
    "\n",
    "        self._embed_and_store(texts_to_embed, metadata)\n",
    "        self.save_db()\n",
    "\n",
    "        #logging token usage\n",
    "        print(f\"Contextual Vector database loaded and saved. Total chunks processed: {len(texts_to_embed)}\")\n",
    "        print(f\"Total input tokens without caching: {self.token_counts['input']}\")\n",
    "        print(f\"Total output tokens: {self.token_counts['output']}\")\n",
    "        print(f\"Total input tokens written to cache: {self.token_counts['cache_creation']}\")\n",
    "        print(f\"Total input tokens read from cache: {self.token_counts['cache_read']}\")\n",
    "        \n",
    "        total_tokens = self.token_counts['input'] + self.token_counts['cache_read'] + self.token_counts['cache_creation']\n",
    "        savings_percentage = (self.token_counts['cache_read'] / total_tokens) * 100 if total_tokens > 0 else 0\n",
    "        print(f\"Total input token savings from prompt caching: {savings_percentage:.2f}% of all input tokens used were read from cache.\")\n",
    "        print(\"Tokens read from cache come at a 90 percent discount!\")\n",
    "\n",
    "    def _embed_and_store(self, texts: List[str], data: List[Dict[str, Any]]):\n",
    "        batch_size = 100\n",
    "        result = []\n",
    "        with tqdm(total=len(texts), desc=\"Embedding chunks\") as pbar:\n",
    "            for i in range(0, len(texts), batch_size):\n",
    "                batch = texts[i : i + batch_size]\n",
    "                response = self.openai_client.embeddings.create(\n",
    "                    input = batch,\n",
    "                    model = \"text-embedding-3-small\"\n",
    "                )\n",
    "                batch_embeddings = [item.embedding for item in response.data]\n",
    "                result.extend(batch_embeddings)\n",
    "                pbar.update(len(batch))\n",
    "\n",
    "        self.embeddings = result\n",
    "        self.metadata = data\n",
    "\n",
    "    def search(self, query: str, k: int = 20) -> List[Dict[str, Any]]:\n",
    "        if query in self.query_cache:\n",
    "            query_embedding = self.query_cache[query]\n",
    "        else:\n",
    "            response = self.openai_client.embeddings.create(\n",
    "                input = [query],\n",
    "                model = \"text-embedding-3-small\"\n",
    "            )\n",
    "            query_embedding = response.data[0].embedding\n",
    "            self.query_cache[query] = query_embedding\n",
    "\n",
    "        if not self.embeddings:\n",
    "            raise ValueError(\"No data loaded in the vector database.\")\n",
    "\n",
    "        similarities = np.dot(self.embeddings, query_embedding)\n",
    "        top_indices = np.argsort(similarities)[::-1][:k]\n",
    "        \n",
    "        top_results = []\n",
    "        for idx in top_indices:\n",
    "            result = {\n",
    "                \"metadata\": self.metadata[idx],\n",
    "                \"similarity\": float(similarities[idx]),\n",
    "            }\n",
    "            top_results.append(result)\n",
    "        return top_results\n",
    "\n",
    "    def save_db(self):\n",
    "        data = {\n",
    "            \"embeddings\": self.embeddings,\n",
    "            \"metadata\": self.metadata,\n",
    "            \"query_cache\": json.dumps(self.query_cache),\n",
    "        }\n",
    "        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)\n",
    "        with open(self.db_path, \"wb\") as file:\n",
    "            pickle.dump(data, file)\n",
    "\n",
    "    def load_db(self):\n",
    "        if not os.path.exists(self.db_path):\n",
    "            raise ValueError(\"Vector database file not found. Use load_data to create a new database.\")\n",
    "        with open(self.db_path, \"rb\") as file:\n",
    "            data = pickle.load(file)\n",
    "        self.embeddings = data[\"embeddings\"]\n",
    "        self.metadata = data[\"metadata\"]\n",
    "        self.query_cache = json.loads(data[\"query_cache\"])\n",
    "\n",
    "print(\"✅ ContextualVectorDB class ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9b02d5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the contextual dataset...\n",
      "Processing with ContextualVectorDB (this may take a few minutes)...\n",
      "Loading vector database from disk.\n",
      "✅ ContextualVectorDB ready for enhanced retrieval!\n",
      "Database contains 5 contextualized chunks\n",
      "✅ Contextual embeddings have been created and cached successfully!\n"
     ]
    }
   ],
   "source": [
    "# Now let's test the ContextualVectorDB with our properly formatted data\n",
    "print(\"Loading the contextual dataset...\")\n",
    "\n",
    "# Initialize the ContextualVectorDB\n",
    "contextual_db = ContextualVectorDB(\"benefits_wellbeing_contextual\")\n",
    "\n",
    "# Load and process the data with contextual embeddings\n",
    "# Note: This will use Claude to generate context for each chunk and then create enhanced embeddings\n",
    "print(\"Processing with ContextualVectorDB (this may take a few minutes)...\")\n",
    "contextual_db.load_data(contextual_dataset, parallel_threads=1)\n",
    "\n",
    "print(\"✅ ContextualVectorDB ready for enhanced retrieval!\")\n",
    "\n",
    "# Validate the database loaded correctly\n",
    "print(f\"Database contains {len(contextual_db.metadata)} contextualized chunks\")\n",
    "if contextual_db.metadata:\n",
    "    print(\"✅ Contextual embeddings have been created and cached successfully!\")\n",
    "else:\n",
    "    print(\"❌ No data found in contextual database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "272769d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contextual RAG Functions\n",
    "\n",
    "def retrieve_contextual(query, contextual_db, k=3):\n",
    "    \"\"\"Retrieve relevant documents and format context from contextual database\"\"\"\n",
    "    results = contextual_db.search(query, k=k)\n",
    "    context = \"\"\n",
    "    for result in results:\n",
    "        chunk = result['metadata']\n",
    "        # Use the original content for context (the contextualized content was used for better retrieval)\n",
    "        context += f\"\\n{chunk['original_content']}\\n\"\n",
    "    return results, context\n",
    "\n",
    "def answer_query_contextual(query, contextual_db):\n",
    "    \"\"\"Answer a query using the Contextual RAG pipeline\"\"\"\n",
    "    documents, context = retrieve_contextual(query, contextual_db)\n",
    "    prompt = f\"\"\" ### SYSTEM ###\n",
    "    You are **Uniswap Benefits Assistant**.\n",
    "\n",
    "    You have been provided with relevant company documents to answer employee questions.\n",
    "\n",
    "    **Workflow for this query:**\n",
    "    1. **Analyze the user question**: {query}\n",
    "    2. **Review the provided context** below for relevant information\n",
    "    3. **Write a natural-language answer** following these rules:\n",
    "    • Use only facts that appear verbatim in the provided context\n",
    "    • If the information isn't in the context, reply: \"I don't have that information in the provided context.\"\n",
    "    • Compose the most **expansive, detailed answer possible** by weaving together **every relevant fact** found in the context—rephrasing, grouping, and elaborating on those facts for clarity and flow\n",
    "    • You may explain terms, list related details, and provide a logical structure\n",
    "    • **Never introduce information that is not stated verbatim in the context**\n",
    "    4. **Do not** provide preamble such as \"Here is the answer\" or \"Based on the documents\"\n",
    "    5. **Always append exactly**: \"Double-check with Julian or Megan for any of this information!\"\n",
    "\n",
    "    ### USER QUESTION ###\n",
    "    {query}\n",
    "\n",
    "    ### CONTEXT ###\n",
    "    {context}\n",
    "\n",
    "    ### RESPONSE ###\"\"\"\n",
    "    \n",
    "    response = client.messages.create(\n",
    "        model=\"claude-sonnet-4-20250514\", #output should use a stronger model than context enrichment models\n",
    "        max_tokens=2500,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0 #creates a deterministic, more factual response\n",
    "    )\n",
    "    # Handle the response content properly\n",
    "    try:\n",
    "        if hasattr(response.content[0], 'text'):\n",
    "            return response.content[0].text\n",
    "        else:\n",
    "            return str(response.content[0])\n",
    "    except (AttributeError, IndexError):\n",
    "        return str(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "25910713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TESTING CONTEXTUAL RAG SYSTEM ===\n",
      "\n",
      "1. Query: Do we have any sort of discounts on rental cars?\n",
      "--------------------------------------------------\n",
      "Contextual RAG Answer: Yes, Uniswap offers discounts on rental cars through partnerships with two major rental car companies:\n",
      "\n",
      "**Hertz Discounted Car Rentals**: Uniswap has partnered with Hertz to provide savings on rental ...\n",
      "✅ Contextual RAG working!\n",
      "\n",
      "2. Query: What gym benefits are available?\n",
      "--------------------------------------------------\n",
      "Contextual RAG Answer: Uniswap offers gym benefits through a partnership with Equinox. The company has partnered with Equinox to offer you $165 off your monthly membership fees.\n",
      "\n",
      "If you're not near a club location, you can ...\n",
      "✅ Contextual RAG working!\n",
      "\n",
      "3. Query: How does parental leave work?\n",
      "--------------------------------------------------\n",
      "Contextual RAG Answer: Parental leave at Uniswap is designed to support new parents through a comprehensive process managed in partnership with Cocoon. Here's how it works:\n",
      "\n",
      "**Leave Duration and Pay:**\n",
      "- Non-birthing/Patern...\n",
      "✅ Contextual RAG working!\n",
      "\n",
      "4. Query: What learning opportunities does the company provide?\n",
      "--------------------------------------------------\n",
      "Contextual RAG Answer: The company provides several learning opportunities for employees:\n",
      "\n",
      "**Learning & Development Allowance**: After 3 months with Uniswap Labs, you're eligible for an annual educational reimbursement up t...\n",
      "✅ Contextual RAG working!\n",
      "\n",
      "5. Query: Are there any financial wellbeing benefits?\n",
      "--------------------------------------------------\n",
      "Contextual RAG Answer: Yes, Uniswap offers several financial wellbeing benefits to support employees' financial health and planning.\n",
      "\n",
      "The primary financial wellbeing benefit is **SoFi Financial Wellbeing**, which allows you...\n",
      "✅ Contextual RAG working!\n",
      "\n",
      "\n",
      "=== CONTEXTUAL RAG SYSTEM STATUS ===\n",
      "Your contextual RAG system is set up to:\n",
      "• Use Claude to generate situational context for each chunk\n",
      "• Create enhanced embeddings with contextual information\n",
      "• Provide more accurate retrieval for complex queries\n",
      "• Maintain original content for final answers\n",
      "\n",
      "✅ Ready for production use with benefits_wellbeing_contextual dataset!\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive Testing of Contextual RAG vs Basic RAG\n",
    "print(\"=== TESTING CONTEXTUAL RAG SYSTEM ===\\n\")\n",
    "\n",
    "# Test queries that should benefit from contextual understanding\n",
    "test_queries = [\n",
    "    \"Do we have any sort of discounts on rental cars?\",\n",
    "    \"What gym benefits are available?\", \n",
    "    \"How does parental leave work?\",\n",
    "    \"What learning opportunities does the company provide?\",\n",
    "    \"Are there any financial wellbeing benefits?\"\n",
    "]\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"{i}. Query: {query}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Get contextual RAG answer\n",
    "    try:\n",
    "        contextual_answer = answer_query_contextual(query, contextual_db)\n",
    "        print(f\"Contextual RAG Answer: {contextual_answer[:200]}...\")\n",
    "        print(\"✅ Contextual RAG working!\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Contextual RAG Error: {e}\\n\")\n",
    "\n",
    "print(\"\\n=== CONTEXTUAL RAG SYSTEM STATUS ===\")\n",
    "print(\"Your contextual RAG system is set up to:\")\n",
    "print(\"• Use Claude to generate situational context for each chunk\")\n",
    "print(\"• Create enhanced embeddings with contextual information\")\n",
    "print(\"• Provide more accurate retrieval for complex queries\")\n",
    "print(\"• Maintain original content for final answers\")\n",
    "print(\"\\n✅ Ready for production use with benefits_wellbeing_contextual dataset!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa64e90",
   "metadata": {},
   "source": [
    "# COMBINED NAIVE RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d26485a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 benefits chunks\n",
      "Loaded 77 handbook chunks\n",
      "✅ Created combined dataset with 82 total chunks\n",
      "   - Benefits & Wellbeing: 5 chunks\n",
      "   - Employee Handbook: 77 chunks\n",
      "✅ Saved to: data/combined_documents.json\n"
     ]
    }
   ],
   "source": [
    "## Creating a Combined VectorDB with Multiple Documents\n",
    "\n",
    "# Let's create a combined dataset that includes both benefits_wellbeing and employee_handbook\n",
    "def create_combined_dataset():\n",
    "    \"\"\"\n",
    "    Create a combined dataset with both benefits_wellbeing and employee_handbook documents\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load both JSON files\n",
    "    with open('data/benefits_wellbeing.json', 'r') as f:\n",
    "        benefits_data = json.load(f)\n",
    "    \n",
    "    with open('data/employee_handbook.json', 'r') as f:\n",
    "        handbook_data = json.load(f)\n",
    "    \n",
    "    print(f\"Loaded {len(benefits_data)} benefits chunks\")\n",
    "    print(f\"Loaded {len(handbook_data)} handbook chunks\")\n",
    "    \n",
    "    def transform_to_combined_format(raw_data, doc_id, doc_type):\n",
    "        \"\"\"Transform data to VectorDB format with document identification\"\"\"\n",
    "        doc = {\n",
    "            \"doc_id\": doc_id,\n",
    "            \"original_uuid\": f\"{doc_id}_uuid\",\n",
    "            \"doc_type\": doc_type,  # Add document type for easier filtering\n",
    "            \"chunks\": []\n",
    "        }\n",
    "        \n",
    "        for i, item in enumerate(raw_data):\n",
    "            chunk = {\n",
    "                \"chunk_id\": f\"{doc_id}_chunk_{i}\",\n",
    "                \"original_index\": i,\n",
    "                \"content\": item[\"text\"],\n",
    "                \"heading\": item[\"chunk_heading\"],\n",
    "                \"link\": item[\"chunk_link\"],\n",
    "                \"doc_type\": doc_type,  # Also add to chunk metadata\n",
    "                \"source_doc\": doc_id  # Clear source identification\n",
    "            }\n",
    "            doc[\"chunks\"].append(chunk)\n",
    "        \n",
    "        return doc\n",
    "    \n",
    "    # Transform both datasets\n",
    "    benefits_doc = transform_to_combined_format(benefits_data, \"benefits_wellbeing\", \"benefits\")\n",
    "    handbook_doc = transform_to_combined_format(handbook_data, \"employee_handbook\", \"handbook\")\n",
    "    \n",
    "    # Combine into a single dataset\n",
    "    combined_dataset = [benefits_doc, handbook_doc]\n",
    "    \n",
    "    # Save the combined dataset\n",
    "    output_file = 'data/combined_documents.json'\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(combined_dataset, f, indent=2)\n",
    "    \n",
    "    total_chunks = len(benefits_doc[\"chunks\"]) + len(handbook_doc[\"chunks\"])\n",
    "    print(f\"✅ Created combined dataset with {total_chunks} total chunks\")\n",
    "    print(f\"   - Benefits & Wellbeing: {len(benefits_doc['chunks'])} chunks\")\n",
    "    print(f\"   - Employee Handbook: {len(handbook_doc['chunks'])} chunks\")\n",
    "    print(f\"✅ Saved to: {output_file}\")\n",
    "    \n",
    "    return combined_dataset\n",
    "\n",
    "# Create the combined dataset\n",
    "combined_dataset = create_combined_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5fdc6b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating combined VectorDB with both documents...\n",
      "Loading vector database from disk.\n",
      "✅ Combined VectorDB ready! Total chunks: 82\n"
     ]
    }
   ],
   "source": [
    "# Initialize a combined VectorDB\n",
    "print(\"Creating combined VectorDB with both documents...\")\n",
    "\n",
    "# Initialize the VectorDB for combined documents\n",
    "combined_db = VectorDB(\"combined_documents\")\n",
    "combined_db.load_data(combined_dataset)\n",
    "\n",
    "total_chunks = sum(len(doc['chunks']) for doc in combined_dataset)\n",
    "print(f\"✅ Combined VectorDB ready! Total chunks: {total_chunks}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4c1e3ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced RAG Functions for Combined Database\n",
    "\n",
    "def retrieve_combined(query, combined_db, k=5):\n",
    "    \"\"\"Retrieve relevant documents from combined database with source information\"\"\"\n",
    "    results = combined_db.search(query, k=k)\n",
    "    context = \"\"\n",
    "    sources = []\n",
    "    \n",
    "    for result in results:\n",
    "        chunk = result['metadata']\n",
    "        \n",
    "        # Extract source information - handle the actual metadata structure\n",
    "        doc_id = chunk.get('doc_id', 'unknown_doc')\n",
    "        chunk_id = chunk.get('chunk_id', 'unknown_chunk')\n",
    "        \n",
    "        # Determine source document from doc_id\n",
    "        if 'benefits' in doc_id.lower():\n",
    "            source_doc = 'benefits_wellbeing'\n",
    "        elif 'handbook' in doc_id.lower() or 'employee' in doc_id.lower():\n",
    "            source_doc = 'employee_handbook'\n",
    "        else:\n",
    "            source_doc = doc_id\n",
    "        \n",
    "        # Try to extract heading from content (first line if it starts with #)\n",
    "        content = chunk.get('content', '')\n",
    "        heading = 'Unknown Section'\n",
    "        content_lines = content.split('\\n')\n",
    "        for line in content_lines[:3]:  # Check first 3 lines\n",
    "            if line.strip().startswith('#'):\n",
    "                heading = line.strip().replace('#', '').strip()\n",
    "                break\n",
    "        \n",
    "        # If no heading found, use chunk_id as fallback\n",
    "        if heading == 'Unknown Section':\n",
    "            heading = chunk_id\n",
    "        \n",
    "        # Include source information in context\n",
    "        source_info = f\"[Source: {source_doc} - {heading}]\"\n",
    "        context += f\"\\n{source_info}\\n{content}\\n\"\n",
    "        sources.append({\n",
    "            'source_doc': source_doc,\n",
    "            'heading': heading,\n",
    "            'similarity': result['similarity']\n",
    "        })\n",
    "    \n",
    "    return results, context, sources\n",
    "\n",
    "def answer_query_combined(query, combined_db):\n",
    "    \"\"\"Answer a query using the Combined RAG pipeline\"\"\"\n",
    "    documents, context, sources = retrieve_combined(query, combined_db)\n",
    "    \n",
    "    # Create source summary\n",
    "    source_summary = \"Sources consulted:\\n\"\n",
    "    for source in sources:\n",
    "        source_summary += f\"• {source['source_doc']}: {source['heading']} (similarity: {source['similarity']:.3f})\\n\"\n",
    "    \n",
    "    prompt = f\"\"\" ### SYSTEM ###\n",
    "    You are **Uniswap Employee Assistant**.\n",
    "\n",
    "    You have been provided with relevant company documents from multiple sources to answer employee questions.\n",
    "\n",
    "    **Workflow for this query:**\n",
    "    1. **Analyze the user question**: {query}\n",
    "    2. **Review the provided context** below for relevant information\n",
    "    3. **Write a natural-language answer** following these rules:\n",
    "    • Use only facts that appear verbatim in the provided context\n",
    "    • If the information isn't in the context, reply: \"I don't have that information in the provided context.\"\n",
    "    • Compose the most **expansive, detailed answer possible** by weaving together **every relevant fact** found in the context—rephrasing, grouping, and elaborating on those facts for clarity and flow\n",
    "    • You may explain terms, list related details, and provide a logical structure\n",
    "    • **Never introduce information that is not stated verbatim in the context**\n",
    "    • When referencing information, mention which document type it comes from (e.g., \"According to the benefits documentation...\" or \"The employee handbook states...\")\n",
    "    4. **Do not** provide preamble such as \"Here is the answer\" or \"Based on the documents\"\n",
    "    5. **Always append exactly**: \"Double-check with Julian or Megan for any of this information!\"\n",
    "\n",
    "    ### USER QUESTION ###\n",
    "    {query}\n",
    "\n",
    "    ### CONTEXT ###\n",
    "    {context}\n",
    "\n",
    "    ### RESPONSE ###\"\"\"\n",
    "    \n",
    "    response = client.messages.create(\n",
    "        model=\"claude-sonnet-4-20250514\",\n",
    "        max_tokens=500,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    # Handle the response content properly\n",
    "    try:\n",
    "        answer = response.content[0].text\n",
    "    except AttributeError:\n",
    "        answer = str(response.content[0])\n",
    "    \n",
    "    return answer, source_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70497c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking metadata structure in combined_db...\n",
      "Sample metadata: {'doc_id': 'employee_handbook', 'original_uuid': 'employee_handbook_uuid', 'chunk_id': 'employee_handbook_chunk_58', 'original_index': 58, 'content': '##'}\n",
      "Metadata keys: ['doc_id', 'original_uuid', 'chunk_id', 'original_index', 'content']\n"
     ]
    }
   ],
   "source": [
    "# First, let's check what the actual metadata structure looks like\n",
    "print(\"Checking metadata structure in combined_db...\")\n",
    "test_results = combined_db.search(\"test\", k=1)\n",
    "if test_results:\n",
    "    print(\"Sample metadata:\", test_results[0]['metadata'])\n",
    "    print(\"Metadata keys:\", list(test_results[0]['metadata'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "17b094a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Tell me about the company's gym benefits\n",
      "\n",
      "Sources consulted:\n",
      "• employee_handbook: Employee Benefits {employee-benefits} (similarity: 0.470)\n",
      "• benefits_wellbeing: Health Benefits (similarity: 0.424)\n",
      "• benefits_wellbeing: 401k & Financial Benefits (similarity: 0.393)\n",
      "• employee_handbook: Phones (similarity: 0.356)\n",
      "• employee_handbook: Reasonable Accommodations:  Disability, Nursing Mothers and Religious  {reasonable-accommodations:-disability,-nursing-mothers-and-religious} (similarity: 0.339)\n",
      "\n",
      "Combined Answer: Based on the provided company documents, I don't have information about gym benefits in the provided context. \n",
      "\n",
      "The employee handbook and benefits documentation detail various wellness and health benefits including medical coverage through Anthem Blue Cross and Kaiser, dental plans through Guardian, vision insurance through VSP, access to One Medical, Maven for fertility and family planning, and an Employee Assistance Program for counseling services. The company also provides financial benefits like a 401k plan, education reimbursement up to $1,500 annually, home office setup reimbursement up to $2,000 for remote workers, coworking space reimbursement up to $500 per month, daily lunch and snacks at the NYC headquarters, and a $50 monthly cell phone stipend.\n",
      "\n",
      "However, none of these documents specifically mention gym memberships, fitness center access, or gym-related benefits as part of the company's offerings.\n",
      "\n",
      "Double-check with Julian or Megan for any of this information!\n"
     ]
    }
   ],
   "source": [
    "# Test the combined RAG system with a query that might span both documents\n",
    "test_query = \"Tell me about the company's gym benefits\"\n",
    "answer, sources = answer_query_combined(test_query, combined_db)\n",
    "\n",
    "print(f\"Query: {test_query}\")\n",
    "print(f\"\\n{sources}\")\n",
    "print(f\"Combined Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e23696f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: Available metadata keys in search results:\n",
      "==================================================\n",
      "Available keys in result: ['metadata', 'similarity']\n",
      "Available keys in metadata: ['doc_id', 'original_uuid', 'chunk_id', 'original_index', 'content']\n",
      "Sample metadata: {'doc_id': 'employee_handbook', 'original_uuid': 'employee_handbook_uuid', 'chunk_id': 'employee_handbook_chunk_0', 'original_index': 0, 'content': '## For our team members working outside of New York State:\\n\\nThis Handbook is intended for use by team members in all states where Uniswap Labs has team members, but it also provides certain information applicable only to team members working in New York State. Team members working outside of New York State may be covered by different state-specific policies and benefits, and team members working in certain states may be provided with a state handbook supplement summarizing specific policies or benefits applicable in those states.  \\n\\nNeither this handbook nor any other communication whether oral or written, is intended in any way to create a contract of employment. Also, this handbook cannot address every situation that may arise in the workplace, and Uniswap Labs reserves the right to flexibly address unique situations.\\n\\n*We hope your employment with us will be mutually beneficial and rewarding.*   \\n*Welcome to the team\\\\!* \\n\\n# A Letter from Hayden Adams \\n\\nUniswap Labs is unique because of our people. Ours is a performance-driven and collaborative culture. We hold ourselves to high standards and are passionate about the role we play in shaping web3 through infrastructure and products. Our goals are ambitious, and our leaders are empowered to build lean teams where each person has an opportunity to make a significant impact. Our team members are multifaceted, with plenty of interests outside work, as writers, parents, musicians, athletes, artists and more. We believe this is an important part of building a culture of creativity, which manifests through the novel products we deliver to the world. \\n\\n# At-Will Employment {#at-will-employment}\\n\\nEmployment with Uniswap Labs is “at-will”. This means that employment may be terminated at any time by the employee or Uniswap Labs with or without cause, and with or without advance notice. The at-will relationship includes the right to hire, transfer, promote, reclassify, layoff, discipline, terminate or change any term or condition of employment (except for at-will employment itself) at any time with or without cause or advance notice. Our policy of “at will” employment cannot be changed except by a formal written agreement specifically entered into for this purpose signed by a member of the executive team.  \\n\\nNeither this employee handbook, nor any policy or practice of Uniswap Labs, is intended to imply continued or guaranteed employment, or otherwise limit in any way the policy of at-will employment. In describing Uniswap Labs’ policies and procedures, this handbook does not obligate Uniswap Labs to follow any particular procedure in the course of imposing discipline or terminating employment.\\n\\nOur goal is to have the best team possible, and this means having the best people possible. Your experience with Uniswap Labs should be mutually beneficial; of course we want to grow our Uniswap Labs, and we also want to foster the growth and development of all our team members. If we’re not holding up our end of the bargain, make sure to let us know.\\n\\n# \\n\\n# Vision, Mission and Values\\n\\nOur Vision  \\nWe envision a world where everyone exchanges value through fair, accessible markets on the internet. In this new economy, value is global, within reach, and flows to creators and contributors. Uniswap Labs builds foundational products and infrastructure to bring this vision to life. \\n\\nOur Mission  \\nUnlock universal ownership and exchange.'}\n",
      "\n",
      "\n",
      "Testing Combined VectorDB with various queries:\n",
      "============================================================\n",
      "\n",
      "1. Query: What is our at-will employment policy?\n",
      "----------------------------------------\n",
      "Top sources found:\n",
      "   1. employee_handbook - For our team members working outside of New York State: (similarity: 0.446)\n",
      "   2. employee_handbook - General Anti-Retaliation Policy (similarity: 0.411)\n",
      "\n",
      "\n",
      "2. Query: What gym benefits do we have?\n",
      "----------------------------------------\n",
      "Top sources found:\n",
      "   1. employee_handbook - Employee Benefits {employee-benefits} (similarity: 0.415)\n",
      "   2. benefits_wellbeing - Health Benefits (similarity: 0.411)\n",
      "\n",
      "\n",
      "3. Query: What are our company principles?\n",
      "----------------------------------------\n",
      "Top sources found:\n",
      "   1. employee_handbook - **Uniswap Principles | Uni-code** (similarity: 0.510)\n",
      "   2. employee_handbook - 4.5       \tHow the Company Complies with Anti-Corruption Laws (similarity: 0.455)\n",
      "\n",
      "\n",
      "4. Query: How does parental leave work?\n",
      "----------------------------------------\n",
      "Top sources found:\n",
      "   1. employee_handbook - Parental and Family Leave  {parental-and-family-leave} (similarity: 0.548)\n",
      "   2. benefits_wellbeing - Leaves (similarity: 0.513)\n",
      "\n",
      "\n",
      "5. Query: What does it mean to be 'people first'?\n",
      "----------------------------------------\n",
      "Top sources found:\n",
      "   1. employee_handbook - **Uniswap Principles | Uni-code** (similarity: 0.335)\n",
      "   2. employee_handbook - Relationships in the Workplace {relationships-in-the-workplace} (similarity: 0.322)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's first debug what keys are available in the metadata\n",
    "test_query_debug = \"What is our at-will employment policy?\"\n",
    "\n",
    "# Fix: Use combined_db instead of the empty contextual_db\n",
    "results = combined_db.search(test_query_debug, k=3)\n",
    "\n",
    "print(\"Debug: Available metadata keys in search results:\")\n",
    "print(\"=\" * 50)\n",
    "if results:\n",
    "    first_result = results[0]\n",
    "    print(f\"Available keys in result: {list(first_result.keys())}\")\n",
    "    print(f\"Available keys in metadata: {list(first_result['metadata'].keys())}\")\n",
    "    print(f\"Sample metadata: {first_result['metadata']}\")\n",
    "else:\n",
    "    print(\"No results found!\")\n",
    "\n",
    "# Let's test some specific queries that demonstrate the power of combined search\n",
    "\n",
    "test_queries = [\n",
    "    \"What is our at-will employment policy?\",  # Should find employee handbook\n",
    "    \"What gym benefits do we have?\",           # Should find benefits document  \n",
    "    \"What are our company principles?\",        # Should find employee handbook\n",
    "    \"How does parental leave work?\",           # Should find benefits document\n",
    "    \"What does it mean to be 'people first'?\" # Should find employee handbook values\n",
    "]\n",
    "\n",
    "print(\"\\n\\nTesting Combined VectorDB with various queries:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\n{i}. Query: {query}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Use the working retrieve_combined function that properly handles metadata\n",
    "    results, context, sources = retrieve_combined(query, combined_db, k=3)\n",
    "    \n",
    "    print(\"Top sources found:\")\n",
    "    for j, source in enumerate(sources[:2]):  # Show top 2 results\n",
    "        print(f\"   {j+1}. {source['source_doc']} - {source['heading']} (similarity: {source['similarity']:.3f})\")\n",
    "    \n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92578d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Combined VectorDB with various queries:\n",
      "============================================================\n",
      "\n",
      "1. Query: What is our at-will employment policy?\n",
      "Answer: Employment with Uniswap Labs is \"at-will\". This means that employment may be terminated at any time by the employee or Uniswap Labs with or without cause, and with or without advance notice. The at-will relationship includes the right to hire, transfer, promote, reclassify, layoff, discipline, terminate or change any term or condition of employment (except for at-will employment itself) at any time with or without cause or advance notice.\n",
      "\n",
      "The policy of \"at will\" employment cannot be changed except by a formal written agreement specifically entered into for this purpose signed by a member of the executive team. Neither the employee handbook, nor any policy or practice of Uniswap Labs, is intended to imply continued or guaranteed employment, or otherwise limit in any way the policy of at-will employment. In describing Uniswap Labs' policies and procedures, the handbook does not obligate Uniswap Labs to follow any particular procedure in the course of imposing discipline or terminating employment.\n",
      "\n",
      "The handbook itself is not intended in any way to create a contract of employment, and it cannot address every situation that may arise in the workplace. Uniswap Labs reserves the right to flexibly address unique situations. The company's goal is to have the best team possible, which means having the best people possible, and they want the experience with Uniswap Labs to be mutually beneficial for both the company's growth and the growth and development of all team members.\n",
      "\n",
      "Double-check with Julian or Megan for any of this information!\n",
      "----------------------------------------\n",
      "Top sources found:\n",
      "   1. employee_handbook - For our team members working outside of New York State: (similarity: 0.446)\n",
      "   2. employee_handbook - General Anti-Retaliation Policy (similarity: 0.411)\n",
      "   3. employee_handbook - Wage and Hours/Attendance {wage-and-hours/attendance} (similarity: 0.406)\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "2. Query: What gym benefits do we have?\n",
      "Answer: I don't have that information in the provided context. The benefits listed include computer equipment, team building events, daily lunch and snacks for NYC headquarters, assistance programs, education reimbursement, home office setup reimbursement, coworking space reimbursement, phone stipends, and various leave policies, but there is no mention of gym benefits or fitness-related perks.\n",
      "\n",
      "Double-check with Julian or Megan for any of this information!\n",
      "----------------------------------------\n",
      "Top sources found:\n",
      "   1. employee_handbook - Employee Benefits {employee-benefits} (similarity: 0.415)\n",
      "   2. benefits_wellbeing - Health Benefits (similarity: 0.411)\n",
      "   3. benefits_wellbeing - 401k & Financial Benefits (similarity: 0.377)\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "3. Query: What are our company principles?\n",
      "Answer: Uniswap operates according to five core principles, collectively called \"Unicode,\" which serve as daily guideposts for how the company interacts with each other, users, and the community:\n",
      "\n",
      "**People First** forms the foundation of Uniswap's approach. The company believes that easy, safe, fair value transfer on the internet can improve people's lives, with access, security and experience at the center of everything they do. By pursuing decentralization, interoperability, and durability, they align with users over the long-term. Internally, people are considered the greatest asset, and the company strives for an environment where everyone can make an incredible impact. They share direct, kind feedback for improvement, and when advocating for ideas, technical tradeoffs, or business goals, they start with why — explaining why it's better for users and the company.\n",
      "\n",
      "**Simple** represents their craft of maintaining clarity in complexity. In a complex field, they create clarity and simplicity by writing and building in human terms that everyone can understand. This philosophy shows up in the design and language of their user experience, across their code, and in how they communicate with the world and each other. They are deliberate in the words and images they use.\n",
      "\n",
      "**Pink** embodies their playful yet serious approach. They love pink both conceptually and in real life, viewing disruption of the status quo as fun. They hold each other accountable to do serious work without taking themselves too seriously. They love unicorns and bring whimsy into their experiments and day-to-day operations. The people-first, internet-native financial system they're building welcomes anyone.\n",
      "\n",
      "**Push Through Ambiguity Together** acknowledges the uncertain nature of startup life, especially at the frontier. They are at peace with uncertainty and push through resistance, showing up ready to explore new ideas with conviction that their mission is worthwhile. When things get hard, they stay on the same team and create scalable solutions to reduce ambiguity in pursuit of their mission. They don't assume shared knowledge or beliefs across their team or users, seeking to understand others' motivations. When disagreeing, they assume positive intent and default to trust.\n",
      "\n",
      "**Build to last, iterate fast** reflects their long-term vision combined with agile execution. They see through today's challenges into tomorrow's possibilities, avoiding short-term thinking and distractions from narratives and prices. They aim to move fast, learn from mistakes, and ship when ready. Where their opinions bring safety, simplicity, and new choices in users' best interests, they express them. This long-term view contributes significantly to their beloved brand status, which they must protect.\n",
      "\n",
      "Double-check with Julian or Megan for any of this information!\n",
      "----------------------------------------\n",
      "Top sources found:\n",
      "   1. employee_handbook - **Uniswap Principles | Uni-code** (similarity: 0.510)\n",
      "   2. employee_handbook - 4.5       \tHow the Company Complies with Anti-Corruption Laws (similarity: 0.455)\n",
      "   3. employee_handbook - For our team members working outside of New York State: (similarity: 0.421)\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "4. Query: How does parental leave work?\n",
      "Answer: Uniswap offers comprehensive parental leave benefits designed to support team members during the transition into parenthood. The company provides paid leave to any team member who needs to care for a new addition to their family, whether by birth, adoption, or placement.\n",
      "\n",
      "**Leave Duration and Eligibility**\n",
      "\n",
      "Birthing mothers are entitled to up to 16 weeks (4 months) of paid parental leave, while all other parents are entitled to up to 12 weeks (3 months). Regular full-time team members are eligible for this policy on their first day of employment. However, temporary team members and part-time team members are not entitled to leave or benefits under this policy but receive leave, pay and accommodations in accordance with other company policies and applicable laws.\n",
      "\n",
      "**Qualifying Leave Requirements**\n",
      "\n",
      "Uniswap Parental Leave commences upon the birth of a child or upon the placement of a child with the employee for adoption or foster care. The leave must be used within 12 months of the child's birth or placement and runs concurrently with any other leave or benefits for which the employee is eligible, such as short-term disability leave or state paid family leave benefits. This includes any period of disability due to pregnancy, childbirth or related medical conditions, and any period of leave taken to bond with a new child, including foster and adoptive children.\n",
      "\n",
      "**Pay and Benefits During Leave**\n",
      "\n",
      "During the parental leave period, team members receive their regular base pay (which may be paid in part by short term disability or paid family leave benefits), subject to fulfilling all requirements. Uniswap Labs continues to provide group health benefits on the same terms as if the employee had not taken leave, and team members are required to continue making any required contributions. The pay benefits provided by Uniswap Labs supplement any pay benefits to which the employee may be entitled, and in no case will pay from all sources exceed 100% of the employee's regular base salary.\n",
      "\n",
      "**Flexible Leave Options**\n",
      "\n",
      "Parental leave may be taken on an intermittent (non-consecutive) basis with the approval of the employee's manager and a member of the People Operations team, or to the extent an employee is entitled to intermittent leave under applicable law. An intermittent leave requires a detailed plan of when the team member will be on leave versus working and includes the desired length of each part of the leave used. The People Team and the employee's manager will review and approve this plan.\n",
      "\n",
      "**Application Process**\n",
      "\n",
      "When the need for leave is foreseeable, team members should give at least 30 days' notice of the request for leave. If 30 days' notice is not possible due to medical necessity or for other reasons, you should provide as much notice as possible. Team members are required to apply for all benefits and leaves for which they are eligible, such as short-term disability or paid family leave benefits.\n",
      "\n",
      "**Job Protection and Return to Work**\n",
      "\n",
      "During Uniswap Parental Leave, your job will be held for you in accordance with applicable law. Team members have no greater right to reinstatement under this policy than if they had been continuously employed rather than on leave. The policy does not affect your status as an at-will employee. Uniswap Labs prohibits discrimination or retaliation against any employee for taking parental leave.\n",
      "\n",
      "**State-Specific Benefits**\n",
      "\n",
      "The parental leave policy complements and does not contradict the New York State Paid Family Leave (NYPFL) and the Family and Medical Leave Act (FMLA). For team members in New York State, additional benefits are available through the state's Paid Family Leave program, which provides up to 12 weeks of leave in a 52-week period with partial pay (67% of average weekly wage up to a cap). California-based employees may be eligible for benefits under the California Family Rights Act (CFRA), which provides up to 12 workweeks in a 12-month rolling period for bonding with a new child, among other qualifying reasons.\n",
      "\n",
      "Double-check with Julian or Megan for any of this information!\n",
      "----------------------------------------\n",
      "Top sources found:\n",
      "   1. employee_handbook - Parental and Family Leave  {parental-and-family-leave} (similarity: 0.548)\n",
      "   2. benefits_wellbeing - Leaves (similarity: 0.513)\n",
      "   3. employee_handbook - Requesting PTO for Sick Leave Purposes {requesting-pto-for-sick-leave-purposes} (similarity: 0.422)\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "5. Query: What does it mean to be 'people first'?\n",
      "Answer: Being \"people first\" at Uniswap encompasses both external and internal commitments centered around improving lives and creating an environment where everyone can thrive.\n",
      "\n",
      "Externally, being people first means believing that easy, safe, fair value transfer on the internet can improve people's lives. Access, security and experience is the center of everything Uniswap does. The company pursues decentralization, interoperability, and durability to align with users over the long-term. When advocating for an idea, a technical tradeoff, or a business goal, the approach starts with why — why it's better for the user and the company.\n",
      "\n",
      "Internally, people are considered Uniswap's greatest asset. The company strives for an environment where everyone can make an incredible impact. This commitment shows up through sharing direct, kind feedback so everyone can improve. The people-first approach is also reflected in building a people-first, internet-native financial system that welcomes anyone.\n",
      "\n",
      "The people-first principle connects to Uniswap's broader mission to unlock universal ownership and exchange, working toward a vision where everyone exchanges value through fair, accessible markets on the internet. In this envisioned new economy, value is global, within reach, and flows to creators and contributors.\n",
      "\n",
      "This principle is supported by the company's culture that values team members as multifaceted individuals with interests outside work, as writers, parents, musicians, athletes, artists and more. The company believes this diversity is an important part of building a culture of creativity, which manifests through the novel products delivered to the world. The goal is to have mutually beneficial experiences where the company grows while fostering the growth and development of all team members.\n",
      "\n",
      "Double-check with Julian or Megan for any of this information!\n",
      "----------------------------------------\n",
      "Top sources found:\n",
      "   1. employee_handbook - **Uniswap Principles | Uni-code** (similarity: 0.335)\n",
      "   2. employee_handbook - Relationships in the Workplace {relationships-in-the-workplace} (similarity: 0.322)\n",
      "   3. employee_handbook - Conflict Resolution/Open Door Policy {conflict-resolution/open-door-policy} (similarity: 0.291)\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's test some specific queries that demonstrate the power of combined search\n",
    "\n",
    "test_queries = [\n",
    "    \"What is our at-will employment policy?\",  # Should find employee handbook\n",
    "    \"What gym benefits do we have?\",           # Should find benefits document  \n",
    "    \"What are our company principles?\",        # Should find employee handbook\n",
    "    \"How does parental leave work?\",           # Should find benefits document\n",
    "    \"What does it mean to be 'people first'?\" # Should find employee handbook values\n",
    "]\n",
    "\n",
    "print(\"Testing Combined VectorDB with various queries:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\n{i}. Query: {query}\")\n",
    "    print(f\"Answer: {answer_query_base(query, db)}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Use the working retrieve_combined function that properly handles metadata\n",
    "    results, context, sources = retrieve_combined(query, combined_db, k=5)\n",
    "    \n",
    "    print(\"Top sources found:\")\n",
    "    for j, source in enumerate(sources[:3]):  # Show top 3 results\n",
    "        print(f\"   {j+1}. {source['source_doc']} - {source['heading']} (similarity: {source['similarity']:.3f})\")\n",
    "    print(\"-\" * 40)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0cefe5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Combined VectorDB with various queries (FIXED VERSION):\n",
      "======================================================================\n",
      "\n",
      "1. Query: What is our at-will employment policy?\n",
      "--------------------------------------------------\n",
      "Top sources found:\n",
      "   1. employee_handbook - For our team members working outside of New York State: (similarity: 0.446)\n",
      "   2. employee_handbook - General Anti-Retaliation Policy (similarity: 0.411)\n",
      "\n",
      "\n",
      "2. Query: What gym benefits do we have?\n",
      "--------------------------------------------------\n",
      "Top sources found:\n",
      "   1. employee_handbook - Employee Benefits {employee-benefits} (similarity: 0.415)\n",
      "   2. benefits_wellbeing - Health Benefits (similarity: 0.411)\n",
      "\n",
      "\n",
      "3. Query: What are our company principles?\n",
      "--------------------------------------------------\n",
      "Top sources found:\n",
      "   1. employee_handbook - **Uniswap Principles | Uni-code** (similarity: 0.510)\n",
      "   2. employee_handbook - 4.5       \tHow the Company Complies with Anti-Corruption Laws (similarity: 0.455)\n",
      "\n",
      "\n",
      "4. Query: How does parental leave work?\n",
      "--------------------------------------------------\n",
      "Top sources found:\n",
      "   1. employee_handbook - Parental and Family Leave  {parental-and-family-leave} (similarity: 0.548)\n",
      "   2. benefits_wellbeing - Leaves (similarity: 0.513)\n",
      "\n",
      "\n",
      "5. Query: What does it mean to be 'people first'?\n",
      "--------------------------------------------------\n",
      "Top sources found:\n",
      "   1. employee_handbook - **Uniswap Principles | Uni-code** (similarity: 0.335)\n",
      "   2. employee_handbook - Relationships in the Workplace {relationships-in-the-workplace} (similarity: 0.322)\n",
      "\n",
      "✅ Combined search tests completed!\n",
      "\n",
      "The combined VectorDB successfully searches across both:\n",
      "• Benefits & Wellbeing document (5 chunks)\n",
      "• Employee Handbook document (78+ chunks)\n",
      "\n",
      "This approach allows you to:\n",
      "• Search all company documents in one query\n",
      "• Get source attribution for each result\n",
      "• Combine information from multiple documents in answers\n"
     ]
    }
   ],
   "source": [
    "# FIX for the KeyError issue - Helper function to safely extract metadata\n",
    "def safe_extract_source_info(chunk_metadata):\n",
    "    \"\"\"Safely extract source info from metadata, handling different structures\"\"\"\n",
    "    # Try to get source_doc and heading directly (new format)\n",
    "    source_doc = chunk_metadata.get('source_doc')\n",
    "    heading = chunk_metadata.get('heading')\n",
    "    \n",
    "    if source_doc and heading:\n",
    "        return source_doc, heading\n",
    "    \n",
    "    # Fallback: extract from other fields\n",
    "    doc_id = chunk_metadata.get('doc_id', 'unknown_doc')\n",
    "    chunk_id = chunk_metadata.get('chunk_id', 'unknown_chunk')\n",
    "    \n",
    "    # Determine source document from doc_id\n",
    "    if 'benefits' in doc_id.lower():\n",
    "        source_doc = 'benefits_wellbeing'\n",
    "    elif 'handbook' in doc_id.lower() or 'employee' in doc_id.lower():\n",
    "        source_doc = 'employee_handbook'\n",
    "    else:\n",
    "        source_doc = doc_id\n",
    "    \n",
    "    # Try to extract heading from content\n",
    "    if not heading:\n",
    "        content = chunk_metadata.get('content', '')\n",
    "        heading = 'Unknown Section'\n",
    "        content_lines = content.split('\\n')\n",
    "        for line in content_lines[:3]:\n",
    "            if line.strip().startswith('#'):\n",
    "                heading = line.strip().replace('#', '').strip()\n",
    "                break\n",
    "        \n",
    "        if heading == 'Unknown Section':\n",
    "            heading = chunk_id\n",
    "    \n",
    "    return source_doc, heading\n",
    "\n",
    "# FIXED version of the test queries\n",
    "test_queries = [\n",
    "    \"What is our at-will employment policy?\",  # Should find employee handbook\n",
    "    \"What gym benefits do we have?\",           # Should find benefits document  \n",
    "    \"What are our company principles?\",        # Should find employee handbook\n",
    "    \"How does parental leave work?\",           # Should find benefits document\n",
    "    \"What does it mean to be 'people first'?\" # Should find employee handbook values\n",
    "]\n",
    "\n",
    "print(\"Testing Combined VectorDB with various queries (FIXED VERSION):\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\n{i}. Query: {query}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Get search results to see which documents are retrieved\n",
    "    try:\n",
    "        results = combined_db.search(query, k=3)\n",
    "        \n",
    "        print(\"Top sources found:\")\n",
    "        for j, result in enumerate(results[:2]):  # Show top 2 results\n",
    "            chunk = result['metadata']\n",
    "            source_doc, heading = safe_extract_source_info(chunk)\n",
    "            print(f\"   {j+1}. {source_doc} - {heading} (similarity: {result['similarity']:.3f})\")\n",
    "    except Exception as e:\n",
    "        print(f\"   Error: {e}\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(\"✅ Combined search tests completed!\")\n",
    "print(\"\\nThe combined VectorDB successfully searches across both:\")\n",
    "print(\"• Benefits & Wellbeing document (5 chunks)\")  \n",
    "print(\"• Employee Handbook document (78+ chunks)\")\n",
    "print(\"\\nThis approach allows you to:\")\n",
    "print(\"• Search all company documents in one query\")\n",
    "print(\"• Get source attribution for each result\") \n",
    "print(\"• Combine information from multiple documents in answers\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472422b8",
   "metadata": {},
   "source": [
    "## Creating a Combined Contextual VectorDB\n",
    "\n",
    "For even better performance, you can also create a **Contextual** VectorDB that combines multiple documents. This approach gives you the benefits of:\n",
    "\n",
    "1. **Multiple document sources** - Search across all your company documents\n",
    "2. **Contextual embeddings** - Better retrieval quality through situational context\n",
    "3. **Source attribution** - Know which document provided each piece of information\n",
    "\n",
    "### Key Advantages of Combined Multi-Document RAG:\n",
    "\n",
    "- **Comprehensive answers**: Pull information from multiple sources to give complete responses\n",
    "- **Cross-document insights**: Find connections between different types of company information\n",
    "- **Efficient search**: One search across all documents instead of separate searches\n",
    "- **Better context**: Questions about company policies, benefits, culture all in one place\n",
    "\n",
    "This is especially powerful for employee-facing applications where questions might span HR policies, benefits, company culture, procedures, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "235da326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Combined document RAG setup complete!\n",
      "\n",
      "You now have the tools to:\n",
      "1. Combine multiple documents into a single VectorDB\n",
      "2. Search across all documents simultaneously\n",
      "3. Get source attribution for each retrieved chunk\n",
      "4. Optionally use contextual embeddings for better retrieval\n",
      "\n",
      "This approach scales to any number of documents!\n"
     ]
    }
   ],
   "source": [
    "# Optional: Create a Contextual Combined VectorDB for even better performance\n",
    "# This combines contextual embeddings with multiple document sources\n",
    "\n",
    "def create_combined_contextual_dataset():\n",
    "    \"\"\"\n",
    "    Create a combined dataset for contextual embeddings with both documents\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load both JSON files\n",
    "    with open('data/benefits_wellbeing.json', 'r') as f:\n",
    "        benefits_data = json.load(f)\n",
    "    \n",
    "    with open('data/employee_handbook.json', 'r') as f:\n",
    "        handbook_data = json.load(f)\n",
    "    \n",
    "    # Load the full documents for context\n",
    "    with open('data/Benefits & Wellbeing.md', 'r') as f:\n",
    "        full_benefits_doc = f.read()\n",
    "    \n",
    "    with open('data/Employee Handbook.md', 'r') as f:\n",
    "        full_handbook_doc = f.read()\n",
    "    \n",
    "    def transform_to_contextual_format(raw_data, doc_id, doc_type, full_content):\n",
    "        \"\"\"Transform data to ContextualVectorDB format with document identification\"\"\"\n",
    "        doc = {\n",
    "            \"doc_id\": doc_id,\n",
    "            \"original_uuid\": f\"{doc_id}_uuid\",\n",
    "            \"doc_type\": doc_type,\n",
    "            \"content\": full_content,  # Full document content for contextual embeddings\n",
    "            \"chunks\": []\n",
    "        }\n",
    "        \n",
    "        for i, item in enumerate(raw_data):\n",
    "            chunk = {\n",
    "                \"chunk_id\": f\"{doc_id}_chunk_{i}\",\n",
    "                \"original_index\": i,\n",
    "                \"content\": item[\"text\"],\n",
    "                \"heading\": item[\"chunk_heading\"],\n",
    "                \"link\": item[\"chunk_link\"],\n",
    "                \"doc_type\": doc_type,\n",
    "                \"source_doc\": doc_id\n",
    "            }\n",
    "            doc[\"chunks\"].append(chunk)\n",
    "        \n",
    "        return doc\n",
    "    \n",
    "    # Transform both datasets\n",
    "    benefits_doc = transform_to_contextual_format(\n",
    "        benefits_data, \"benefits_wellbeing\", \"benefits\", full_benefits_doc\n",
    "    )\n",
    "    handbook_doc = transform_to_contextual_format(\n",
    "        handbook_data, \"employee_handbook\", \"handbook\", full_handbook_doc\n",
    "    )\n",
    "    \n",
    "    # Combine into a single dataset\n",
    "    combined_contextual_dataset = [benefits_doc, handbook_doc]\n",
    "    \n",
    "    # Save the combined dataset\n",
    "    output_file = 'data/combined_contextual_documents.json'\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(combined_contextual_dataset, f, indent=2)\n",
    "    \n",
    "    total_chunks = len(benefits_doc[\"chunks\"]) + len(handbook_doc[\"chunks\"])\n",
    "    print(f\"✅ Created combined contextual dataset with {total_chunks} total chunks\")\n",
    "    print(f\"   - Benefits & Wellbeing: {len(benefits_doc['chunks'])} chunks\")\n",
    "    print(f\"   - Employee Handbook: {len(handbook_doc['chunks'])} chunks\")\n",
    "    print(f\"✅ Saved to: {output_file}\")\n",
    "    \n",
    "    return combined_contextual_dataset\n",
    "\n",
    "# Uncomment to create the contextual combined dataset\n",
    "# combined_contextual_dataset = create_combined_contextual_dataset()\n",
    "\n",
    "# To initialize a ContextualVectorDB with combined documents:\n",
    "# combined_contextual_db = ContextualVectorDB(\"combined_contextual_documents\")\n",
    "# combined_contextual_db.load_data(combined_contextual_dataset, parallel_threads=1)\n",
    "\n",
    "print(\"✅ Combined document RAG setup complete!\")\n",
    "print(\"\\nYou now have the tools to:\")\n",
    "print(\"1. Combine multiple documents into a single VectorDB\")\n",
    "print(\"2. Search across all documents simultaneously\") \n",
    "print(\"3. Get source attribution for each retrieved chunk\")\n",
    "print(\"4. Optionally use contextual embeddings for better retrieval\")\n",
    "print(\"\\nThis approach scales to any number of documents!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
