{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "256b8b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def convert_md_to_json(input_file_path, output_file_path):\n",
    "    \"\"\"\n",
    "    Convert markdown file to JSON format for RAG processing.\n",
    "    Splits content by ## headings and includes all subsections within each chunk.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the markdown file\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    # Split content by ## headings (level 2 headings)\n",
    "    # This regex finds lines that start with exactly two # followed by a space\n",
    "    sections = re.split(r'\\n(?=## )', content)\n",
    "    \n",
    "    # Initialize the result list\n",
    "    json_chunks = []\n",
    "    \n",
    "    for section in sections:\n",
    "        # Skip empty sections\n",
    "        if not section.strip():\n",
    "            continue\n",
    "            \n",
    "        # Find the first ## heading in this section\n",
    "        lines = section.split('\\n')\n",
    "        heading_line = None\n",
    "        \n",
    "        for line in lines:\n",
    "            if line.startswith('## '):\n",
    "                heading_line = line\n",
    "                break\n",
    "        \n",
    "        # Skip if no ## heading found (like the initial content before first ##)\n",
    "        if not heading_line:\n",
    "            continue\n",
    "            \n",
    "        # Extract the heading text (remove the ## and strip whitespace)\n",
    "        chunk_heading = heading_line.replace('## ', '').strip()\n",
    "        \n",
    "        # The entire section content (including the heading)\n",
    "        text_content = section.strip()\n",
    "        \n",
    "        # Create the JSON chunk\n",
    "        chunk = {\n",
    "            \"chunk_link\": \"\",  # Empty as requested\n",
    "            \"chunk_heading\": chunk_heading,\n",
    "            \"text\": text_content\n",
    "        }\n",
    "        \n",
    "        json_chunks.append(chunk)\n",
    "    \n",
    "    # Write to JSON file\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(json_chunks, file, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"Conversion complete! Created {len(json_chunks)} chunks.\")\n",
    "    print(f\"Output saved to: {output_file_path}\")\n",
    "    \n",
    "    return json_chunks\n",
    "\n",
    "def preview_chunks(chunks, num_chunks=3):\n",
    "    \"\"\"Preview the first few chunks to verify the conversion\"\"\"\n",
    "    print(f\"\\nPreview of first {min(num_chunks, len(chunks))} chunks:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for i, chunk in enumerate(chunks[:num_chunks]):\n",
    "        print(f\"\\nChunk {i+1}:\")\n",
    "        print(f\"Heading: {chunk['chunk_heading']}\")\n",
    "        print(f\"Text length: {len(chunk['text'])} characters\")\n",
    "        print(f\"Text preview: {chunk['text'][:200]}...\")\n",
    "        print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddf0211c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete! Created 78 chunks.\n",
      "Output saved to: employee_handbook.json\n",
      "\n",
      "Preview of first 3 chunks:\n",
      "==================================================\n",
      "\n",
      "Chunk 1:\n",
      "Heading: For our team members working outside of New York State:\n",
      "Text length: 3425 characters\n",
      "Text preview: ## For our team members working outside of New York State:\n",
      "\n",
      "This Handbook is intended for use by team members in all states where Uniswap Labs has team members, but it also provides certain informatio...\n",
      "------------------------------\n",
      "\n",
      "Chunk 2:\n",
      "Heading: **Uniswap Principles | Uni-code**\n",
      "Text length: 2595 characters\n",
      "Text preview: ## **Uniswap Principles | Uni-code**\n",
      "\n",
      "*Our Uniswap operating principles (Unicode) articulate who we are (our values) and how we work. They are our daily guideposts for how we interact with each other,...\n",
      "------------------------------\n",
      "\n",
      "Chunk 3:\n",
      "Heading: Code of Ethics {#code-of-ethics}\n",
      "Text length: 1944 characters\n",
      "Text preview: ## Code of Ethics {#code-of-ethics}\n",
      "\n",
      "Uniswap Labsâ€™ Code of Ethics is one of the ways we put our UNIcode values into practice. We empower all team members to have their own personal standards and make ...\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    input_file = \"Employee Handbook.md\"  # Update this path\n",
    "    output_file = \"employee_handbook.json\"  # Update this path\n",
    "    \n",
    "    try:\n",
    "        chunks = convert_md_to_json(input_file, output_file)\n",
    "        preview_chunks(chunks)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find the input file '{input_file}'\")\n",
    "        print(\"Please update the input_file path in the script.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during conversion: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
